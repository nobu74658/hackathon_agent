from typing import Dict, Any, List, Optional, Tuple
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from langchain.schema.runnable import RunnablePassthrough
from langchain_openai import ChatOpenAI
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
from datetime import datetime
import json
from enum import Enum

from app.services.conversation_memory import ConversationMemoryService
from app.services.one_on_one_analyzer import OneOnOneAnalyzer
from app.core.config import settings


class QuestionResponse(BaseModel):
    """è³ªå•ç”Ÿæˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ """
    questions: List[str] = Field(description="ç”Ÿæˆã•ã‚ŒãŸè³ªå•ã®ãƒªã‚¹ãƒˆ")
    reasoning: str = Field(description="ãªãœã“ã‚Œã‚‰ã®è³ªå•ãŒå¿…è¦ã‹ã®èª¬æ˜")
    information_needed: List[str] = Field(description="ã¾ã å¿…è¦ãªæƒ…å ±ã®ãƒªã‚¹ãƒˆ")
    completeness_score: int = Field(description="æƒ…å ±ã®å……è¶³åº¦ï¼ˆ0-100ï¼‰")


class ActionPlanResponse(BaseModel):
    """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ """
    action_items: List[Dict[str, Any]] = Field(description="ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒªã‚¹ãƒˆ")
    summary: str = Field(description="å…¨ä½“çš„ãªã‚µãƒãƒªãƒ¼")
    key_improvements: List[str] = Field(description="ä¸»è¦ãªæ”¹å–„ãƒã‚¤ãƒ³ãƒˆ")
    metrics: Dict[str, Any] = Field(description="æˆåŠŸæŒ‡æ¨™")


class DialoguePhase(Enum):
    """ç†æƒ³çš„ãªå¯¾è©±ãƒ•ã‚§ãƒ¼ã‚ºã®å®šç¾©"""
    CURRENT_SITUATION = "current_situation"  # ç¾çŠ¶æŠŠæ¡
    PROBLEM_ANALYSIS = "problem_analysis"   # èª²é¡Œåˆ†æ
    SOLUTION_EXPLORATION = "solution_exploration"  # ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³æ¢ç´¢
    ACTION_PLAN = "action_plan"  # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ä½œæˆ
    EXECUTION_SUPPORT = "execution_support"  # å®Ÿè¡Œæ”¯æ´
    COMPLETED = "completed"  # å®Œäº†


class SocraticQuestionResponse(BaseModel):
    """ã‚½ã‚¯ãƒ©ãƒ†ã‚¹å¼è³ªå•ã®æ§‹é€ """
    question: str = Field(description="ç”Ÿæˆã•ã‚ŒãŸè³ªå•")
    purpose: str = Field(description="ã“ã®è³ªå•ã®ç›®çš„")
    expected_insight: str = Field(description="æœŸå¾…ã•ã‚Œã‚‹æ°—ã¥ã")
    phase: str = Field(description="ç¾åœ¨ã®ãƒ•ã‚§ãƒ¼ã‚º")
    next_phase_condition: str = Field(description="æ¬¡ã®ãƒ•ã‚§ãƒ¼ã‚ºã«é€²ã‚€æ¡ä»¶")


class IdealDialogueManager:
    """ç†æƒ³çš„ãªå¯¾è©±ã‚·ãƒŠãƒªã‚ªã‚’å®Ÿç¾ã™ã‚‹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
    
    def __init__(self, llm):
        self.llm = llm
        self.socratic_parser = PydanticOutputParser(pydantic_object=SocraticQuestionResponse)
        
    async def get_socratic_question(
        self,
        phase: DialoguePhase,
        context: Dict[str, Any],
        user_responses: List[Dict[str, Any]]
    ) -> SocraticQuestionResponse:
        """ã‚½ã‚¯ãƒ©ãƒ†ã‚¹å¼è³ªå•ã‚’ç”Ÿæˆ"""
        
        phase_prompts = {
            DialoguePhase.CURRENT_SITUATION: self._get_current_situation_prompt(),
            DialoguePhase.PROBLEM_ANALYSIS: self._get_problem_analysis_prompt(),
            DialoguePhase.SOLUTION_EXPLORATION: self._get_solution_exploration_prompt(),
            DialoguePhase.ACTION_PLAN: self._get_action_plan_prompt(),
            DialoguePhase.EXECUTION_SUPPORT: self._get_execution_support_prompt()
        }
        
        prompt = phase_prompts.get(phase, self._get_default_prompt())
        
        chain = (
            {
                "context": lambda _: json.dumps(context, ensure_ascii=False),
                "user_responses": lambda _: json.dumps(user_responses, ensure_ascii=False),
                "format_instructions": lambda _: self.socratic_parser.get_format_instructions()
            }
            | prompt
            | self.llm
            | self.socratic_parser
        )
        
        return await chain.ainvoke({})
    
    def _get_current_situation_prompt(self) -> ChatPromptTemplate:
        """ç¾çŠ¶æŠŠæ¡ãƒ•ã‚§ãƒ¼ã‚ºã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return ChatPromptTemplate.from_messages([
            ("system", """
ã‚ãªãŸã¯æ–°äººå–¶æ¥­ãƒãƒ³ã®æˆé•·ã‚’æ”¯æ´ã™ã‚‹AIã‚³ãƒ¼ãƒã§ã™ã€‚
ç¾åœ¨ã¯ã€Œç¾çŠ¶æŠŠæ¡ãƒ•ã‚§ãƒ¼ã‚ºã€ã«ã„ã¾ã™ã€‚

ã€ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã®ç›®çš„ã€‘
- éƒ¨ä¸‹ã®ç¾åœ¨ã®çŠ¶æ³ã‚’åŒ…æ‹¬çš„ã«æŠŠæ¡ã™ã‚‹
- ä¸Šå¸ã®æŠ½è±¡çš„ãªæŒ‡ç¤ºã«å¯¾ã™ã‚‹ç†è§£åº¦ã‚’ç¢ºèªã™ã‚‹
- å£²ä¸ŠçŠ¶æ³ã€é¡§å®¢å¯¾å¿œã®ç¾çŠ¶ã€èª²é¡Œã‚’ä¸€åº¦ã«ç†è§£ã™ã‚‹

ã€è³ªå•ä½œæˆã®åŸå‰‡ã€‘
- 1ã¤ã®è³ªå•ã§è¤‡æ•°ã®æƒ…å ±ã‚’åŠ¹ç‡çš„ã«åé›†
- å…·ä½“çš„ã§ç­”ãˆã‚„ã™ã„æ§‹é€ ã«ã™ã‚‹
- ç¾çŠ¶ã®èª²é¡Œã¨æˆåŠŸä½“é¨“ã‚’åŒæ™‚ã«èãå‡ºã™
- è² è·ã‚’æ¸›ã‚‰ã—ã¤ã¤ã€å¿…è¦ãªæƒ…å ±ã‚’ç¶²ç¾…ã™ã‚‹

ç¾åœ¨ã®å£²ä¸ŠçŠ¶æ³ã€æ™‚é–“é…åˆ†ã€é¡§å®¢ã¨ã®é–¢ä¿‚ã€ä¸Šå¸ã®æŒ‡ç¤ºã¸ã®ç†è§£ã‚’åŒ…æ‹¬çš„ã«èãå‡ºã™è³ªå•ã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}
éå»ã®å›ç­”: {user_responses}

{format_instructions}
"""),
            ("user", "ç¾çŠ¶ã‚’åŒ…æ‹¬çš„ã«æŠŠæ¡ã™ã‚‹ãŸã‚ã®åŠ¹ç‡çš„ãªè³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        ])
    
    def _get_problem_analysis_prompt(self) -> ChatPromptTemplate:
        """èª²é¡Œåˆ†æãƒ•ã‚§ãƒ¼ã‚ºã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return ChatPromptTemplate.from_messages([
            ("system", """
ã‚ãªãŸã¯æ–°äººå–¶æ¥­ãƒãƒ³ã®æˆé•·ã‚’æ”¯æ´ã™ã‚‹AIã‚³ãƒ¼ãƒã§ã™ã€‚
ç¾åœ¨ã¯ã€Œèª²é¡Œåˆ†æãƒ•ã‚§ãƒ¼ã‚ºã€ã«ã„ã¾ã™ã€‚

ã€ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã®ç›®çš„ã€‘
- æˆåŠŸä½“é¨“ã¨ãã®ç†ç”±ã‚’åŠ¹ç‡çš„ã«ç™ºè¦‹ã™ã‚‹
- æŠ½è±¡çš„ãªæŒ‡ç¤ºã®å…·ä½“çš„ãªæ„å‘³ã‚’ç†è§£ã•ã›ã‚‹
- æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®å†ç¾å¯èƒ½æ€§ã‚’ä¸€åº¦ã«æ¢ã‚‹

ã€è³ªå•ä½œæˆã®åŸå‰‡ã€‘
- æˆåŠŸäº‹ä¾‹ã€ãã®ç†ç”±ã€æˆæœã‚’ä¸€åº¦ã«èãå‡ºã™
- ã€Œä½•ãŒã†ã¾ãã„ã£ãŸã‹ï¼Ÿãªãœã†ã¾ãã„ã£ãŸã‹ï¼Ÿã©ã‚“ãªçµæœãŒå‡ºãŸã‹ï¼Ÿã€ã‚’åŒ…æ‹¬çš„ã«è³ªå•
- éƒ¨ä¸‹ã®è‡ªä¿¡ã‚’é«˜ã‚ã¤ã¤ã€åŠ¹ç‡çš„ã«æƒ…å ±åé›†
- ä»–ã®é¡§å®¢ã¸ã®å¿œç”¨å¯èƒ½æ€§ã‚‚å«ã‚ã¦è³ªå•

æœ€ã‚‚è‰¯å¥½ãªé¡§å®¢é–¢ä¿‚ã®äº‹ä¾‹ã€ãã®æˆåŠŸè¦å› ã€å…·ä½“çš„ãªæˆæœã€ä»–ã¸ã®å¿œç”¨å¯èƒ½æ€§ã‚’åŒ…æ‹¬çš„ã«èãå‡ºã™è³ªå•ã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}
éå»ã®å›ç­”: {user_responses}

{format_instructions}
"""),
            ("user", "æˆåŠŸä½“é¨“ã‚’åŒ…æ‹¬çš„ã«åˆ†æã™ã‚‹ãŸã‚ã®åŠ¹ç‡çš„ãªè³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        ])
    
    def _get_solution_exploration_prompt(self) -> ChatPromptTemplate:
        """ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³æ¢ç´¢ãƒ•ã‚§ãƒ¼ã‚ºã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return ChatPromptTemplate.from_messages([
            ("system", """
ã‚ãªãŸã¯æ–°äººå–¶æ¥­ãƒãƒ³ã®æˆé•·ã‚’æ”¯æ´ã™ã‚‹AIã‚³ãƒ¼ãƒã§ã™ã€‚
ç¾åœ¨ã¯ã€Œã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³æ¢ç´¢ãƒ•ã‚§ãƒ¼ã‚ºã€ã«ã„ã¾ã™ã€‚

ã€ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã®ç›®çš„ã€‘
- æˆåŠŸä½“é¨“ã®ä»–ã®é¡§å®¢ã¸ã®å¿œç”¨æ–¹æ³•ã‚’åŠ¹ç‡çš„ã«ç‰¹å®šã™ã‚‹
- æˆ¦ç•¥çš„ãªå„ªå…ˆé †ä½ä»˜ã‘ã‚’ä¸€åº¦ã«æ±ºã‚ã‚‹
- ç¾å®Ÿçš„ã§å®Ÿè¡Œå¯èƒ½ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ±ºå®šã™ã‚‹

ã€è³ªå•ä½œæˆã®åŸå‰‡ã€‘
- é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€å„ªå…ˆé †ä½ã€å…·ä½“çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’åŒ…æ‹¬çš„ã«è³ªå•
- ã€Œã©ã®é¡§å®¢ã«ã€ã€Œã©ã®é †ç•ªã§ã€ã€Œã©ã®ã‚ˆã†ãªæ–¹æ³•ã§ã€ã‚’ä¸€åº¦ã«èãå‡ºã™
- ãƒªã‚½ãƒ¼ã‚¹åˆ¶ç´„ã‚’è€ƒæ…®ã—ãŸç¾å®Ÿçš„ãªè¨ˆç”»ã‚’ç«‹ã¦ã•ã›ã‚‹
- åŠ¹ç‡çš„ãªæˆ¦ç•¥ç«‹æ¡ˆã‚’ä¿ƒé€²

é¡§å®¢ã®åˆ†é¡ã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã™ã‚‹å„ªå…ˆé †ä½ã€å…·ä½“çš„ãªé–¢ä¿‚æ§‹ç¯‰æ–¹æ³•ã‚’åŒ…æ‹¬çš„ã«è€ƒãˆã•ã›ã‚‹è³ªå•ã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}
éå»ã®å›ç­”: {user_responses}

{format_instructions}
"""),
            ("user", "æˆ¦ç•¥çš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³è¨­è¨ˆã®ãŸã‚ã®åŒ…æ‹¬çš„ãªè³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        ])
    
    def _get_action_plan_prompt(self) -> ChatPromptTemplate:
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ä½œæˆãƒ•ã‚§ãƒ¼ã‚ºã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return ChatPromptTemplate.from_messages([
            ("system", """
ã‚ãªãŸã¯æ–°äººå–¶æ¥­ãƒãƒ³ã®æˆé•·ã‚’æ”¯æ´ã™ã‚‹AIã‚³ãƒ¼ãƒã§ã™ã€‚
ç¾åœ¨ã¯ã€Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ä½œæˆãƒ•ã‚§ãƒ¼ã‚ºã€ã«ã„ã¾ã™ã€‚

ã€ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã®ç›®çš„ã€‘
- SMARTç›®æ¨™ã‚’åŠ¹ç‡çš„ã«è¨­å®šã™ã‚‹
- å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€æœŸé™ã€æ¸¬å®šæŒ‡æ¨™ã‚’ä¸€åº¦ã«æ±ºã‚ã‚‹
- å®Ÿç¾å¯èƒ½ã§å®Ÿè¡Œã—ã‚„ã™ã„è¨ˆç”»ã‚’ä½œæˆã™ã‚‹

ã€è³ªå•ä½œæˆã®åŸå‰‡ã€‘
- ã€Œä½•ã‚’ã€ã„ã¤ã¾ã§ã«ã€ã©ã®ã‚ˆã†ã«æ¸¬å®šã™ã‚‹ã‹ã€ã‚’åŒ…æ‹¬çš„ã«è³ªå•
- Specific, Measurable, Achievable, Relevant, Time-boundã®è¦ç´ ã‚’åŠ¹ç‡çš„ã«è¨­å®š
- çŸ­æœŸç›®æ¨™ã¨ä¸­é•·æœŸç›®æ¨™ã‚’åŒæ™‚ã«è€ƒãˆã•ã›ã‚‹
- å®Ÿè¡Œã®å…·ä½“çš„ãªã‚¹ãƒ†ãƒƒãƒ—ã‚‚å«ã‚ã¦è³ªå•

å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹ã€å®Ÿè¡ŒæœŸé™ã€æˆåŠŸã®æ¸¬å®šæ–¹æ³•ã€æœŸå¾…ã•ã‚Œã‚‹æˆæœã‚’åŒ…æ‹¬çš„ã«è¨­å®šã•ã›ã‚‹è³ªå•ã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}
éå»ã®å›ç­”: {user_responses}

{format_instructions}
"""),
            ("user", "SMARTç›®æ¨™ã¨å®Ÿè¡Œè¨ˆç”»ã‚’åŒ…æ‹¬çš„ã«è¨­å®šã™ã‚‹ãŸã‚ã®è³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        ])
    
    def _get_execution_support_prompt(self) -> ChatPromptTemplate:
        """å®Ÿè¡Œæ”¯æ´ãƒ•ã‚§ãƒ¼ã‚ºã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return ChatPromptTemplate.from_messages([
            ("system", """
ã‚ãªãŸã¯æ–°äººå–¶æ¥­ãƒãƒ³ã®æˆé•·ã‚’æ”¯æ´ã™ã‚‹AIã‚³ãƒ¼ãƒã§ã™ã€‚
ç¾åœ¨ã¯ã€Œå®Ÿè¡Œæ”¯æ´ãƒ•ã‚§ãƒ¼ã‚ºã€ã«ã„ã¾ã™ã€‚

ã€ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã®ç›®çš„ã€‘
- å®Ÿè¡Œæ™‚ã®èª²é¡Œã¨è§£æ±ºç­–ã‚’åŠ¹ç‡çš„ã«ç‰¹å®šã™ã‚‹
- ç¶™ç¶šã®ãŸã‚ã®ä»•çµ„ã¿ã¨é€²æ—ç¢ºèªæ–¹æ³•ã‚’ä¸€åº¦ã«æ±ºã‚ã‚‹
- è‡ªå¾‹çš„ãªå•é¡Œè§£æ±ºèƒ½åŠ›ã‚’è‚²æˆã™ã‚‹

ã€è³ªå•ä½œæˆã®åŸå‰‡ã€‘
- ã€Œäºˆæƒ³ã•ã‚Œã‚‹éšœå®³ã€ãã®è§£æ±ºç­–ã€ç¶™ç¶šã®ä»•çµ„ã¿ã€é€²æ—ç¢ºèªæ–¹æ³•ã€ã‚’åŒ…æ‹¬çš„ã«è³ªå•
- æ™‚é–“ç¢ºä¿ã€ã‚¹ã‚­ãƒ«ä¸è¶³ã€ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ç¶­æŒãªã©ã®èª²é¡Œã‚’ä¸€åº¦ã«æ¤œè¨
- é€±æ¬¡ãƒ»æœˆæ¬¡ã®æŒ¯ã‚Šè¿”ã‚Šæ–¹æ³•ã‚‚åŒæ™‚ã«è¨­å®š
- å®Ÿè¡Œã‚’æˆåŠŸã•ã›ã‚‹å…·ä½“çš„ãªå·¥å¤«ã‚’å¼•ãå‡ºã™

å®Ÿè¡Œæ™‚ã®èª²é¡Œäºˆæ¸¬ã€è§£æ±ºç­–ã€ç¶™ç¶šã®ãŸã‚ã®ä»•çµ„ã¿ã€é€²æ—ç¢ºèªæ–¹æ³•ã‚’åŒ…æ‹¬çš„ã«è€ƒãˆã•ã›ã‚‹è³ªå•ã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}
éå»ã®å›ç­”: {user_responses}

{format_instructions}
"""),
            ("user", "å®Ÿè¡ŒæˆåŠŸã®ãŸã‚ã®åŒ…æ‹¬çš„ãªæ”¯æ´ç­–ã‚’è€ƒãˆã‚‹è³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        ])
    
    def _get_default_prompt(self) -> ChatPromptTemplate:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return ChatPromptTemplate.from_messages([
            ("system", """
ã‚ãªãŸã¯æ–°äººå–¶æ¥­ãƒãƒ³ã®æˆé•·ã‚’æ”¯æ´ã™ã‚‹AIã‚³ãƒ¼ãƒã§ã™ã€‚

ã‚½ã‚¯ãƒ©ãƒ†ã‚¹å¼è³ªå•æ³•ã‚’ç”¨ã„ã¦ã€éƒ¨ä¸‹ã®æˆé•·ã‚’ä¿ƒã™è³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}
éå»ã®å›ç­”: {user_responses}

{format_instructions}
"""),
            ("user", "æˆé•·ã‚’ä¿ƒã™åŠ¹æœçš„ãªè³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        ])
    
    def determine_next_phase(
        self,
        current_phase: DialoguePhase,
        user_responses: List[Dict[str, Any]]
    ) -> DialoguePhase:
        """æ¬¡ã®ãƒ•ã‚§ãƒ¼ã‚ºã‚’æ±ºå®š"""
        phase_transitions = {
            DialoguePhase.CURRENT_SITUATION: DialoguePhase.PROBLEM_ANALYSIS,
            DialoguePhase.PROBLEM_ANALYSIS: DialoguePhase.SOLUTION_EXPLORATION,
            DialoguePhase.SOLUTION_EXPLORATION: DialoguePhase.ACTION_PLAN,
            DialoguePhase.ACTION_PLAN: DialoguePhase.EXECUTION_SUPPORT,
            DialoguePhase.EXECUTION_SUPPORT: DialoguePhase.COMPLETED
        }
        
        # å„ãƒ•ã‚§ãƒ¼ã‚ºã§æœ€ä½2-3ã®è³ªå•ã«ç­”ãˆãŸå ´åˆã«æ¬¡ã®ãƒ•ã‚§ãƒ¼ã‚ºã«é€²ã‚€
        current_phase_responses = [
            r for r in user_responses 
            if r.get("phase") == current_phase.value
        ]
        
        if len(current_phase_responses) >= 1:  # 1ã¤ã®å›ç­”ã§æ¬¡ã®ãƒ•ã‚§ãƒ¼ã‚ºã¸
            return phase_transitions.get(current_phase, DialoguePhase.COMPLETED)
        
        return current_phase


class DialogueManager:
    """å¯¾è©±ãƒ•ãƒ­ãƒ¼ã‚’ç®¡ç†ã™ã‚‹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
    
    def __init__(self):
        self.memory_service = ConversationMemoryService()
        self.one_on_one_analyzer = OneOnOneAnalyzer()
        self.llm = ChatOpenAI(
            model=settings.OPENAI_MODEL,
            temperature=0.7,
            api_key=settings.OPENAI_API_KEY
        )
        self.question_parser = PydanticOutputParser(pydantic_object=QuestionResponse)
        self.action_plan_parser = PydanticOutputParser(pydantic_object=ActionPlanResponse)
        
        # ç†æƒ³çš„ãªå¯¾è©±ã‚·ãƒŠãƒªã‚ªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        self.ideal_dialogue_manager = IdealDialogueManager(self.llm)
        
        # ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã®1on1ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†ï¼ˆRedisãŒãªã„å ´åˆã®ä»£æ›¿ï¼‰
        self._in_memory_sessions: Dict[str, Dict[str, Any]] = {}
        
        # ç†æƒ³çš„ãªå¯¾è©±ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†
        self._ideal_dialogue_sessions: Dict[str, Dict[str, Any]] = {}
    
    async def initialize(self):
        """ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–"""
        await self.memory_service.initialize()
    
    async def start_dialogue(
        self,
        session_id: str,
        initial_context: Dict[str, Any]
    ) -> Tuple[List[str], Dict[str, Any]]:
        """å¯¾è©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹"""
        # åˆæœŸè³ªå•ç”Ÿæˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ã‚ãªãŸã¯æ–°äººå–¶æ¥­ãƒãƒ³ã®æˆé•·ã‚’æ”¯æ´ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
            1on1ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å†…å®¹ã‹ã‚‰ã€å–¶æ¥­ã‚¹ã‚­ãƒ«å‘ä¸Šã®ãŸã‚ã®å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«
            å¿…è¦ãªæƒ…å ±ã‚’åé›†ã—ã¾ã™ã€‚
            
            ä»¥ä¸‹ã®æƒ…å ±ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã™ï¼š
            {initial_context}
            
            åŠ¹æœçš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«è¿½åŠ ã§å¿…è¦ãªæƒ…å ±ã‚’ç‰¹å®šã—ã€
            3-5å€‹ã®å…·ä½“çš„ã§ç­”ãˆã‚„ã™ã„è³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
            
            {format_instructions}
            """),
            ("user", "1on1ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å†…å®¹ã‚’åˆ†æã—ã€è¿½åŠ ã§å¿…è¦ãªæƒ…å ±ã‚’åé›†ã™ã‚‹ãŸã‚ã®è³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        ])
        
        # ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰
        chain = (
            {
                "initial_context": RunnablePassthrough(),
                "format_instructions": lambda _: self.question_parser.get_format_instructions()
            }
            | prompt
            | self.llm
            | self.question_parser
        )
        
        # è³ªå•ç”Ÿæˆ
        response = await chain.ainvoke(json.dumps(initial_context, ensure_ascii=False))
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        metadata = {
            "stage": "initial",
            "reasoning": response.reasoning,
            "information_needed": response.information_needed,
            "completeness_score": response.completeness_score
        }
        
        return response.questions, metadata
    
    async def start_ideal_dialogue(
        self,
        session_id: str,
        abstract_instruction: str,
        context: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """ç†æƒ³çš„ãªå¯¾è©±ã‚·ãƒŠãƒªã‚ªã‚’é–‹å§‹"""
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
        self._ideal_dialogue_sessions[session_id] = {
            "phase": DialoguePhase.CURRENT_SITUATION,
            "abstract_instruction": abstract_instruction,
            "user_responses": [],
            "context": context or {},
            "started_at": datetime.now().isoformat()
        }
        
        # æœ€åˆã®è³ªå•ã‚’ç”Ÿæˆ
        return await self.continue_ideal_dialogue(session_id, None)
    
    async def continue_ideal_dialogue(
        self,
        session_id: str,
        user_response: str = None
    ) -> Dict[str, Any]:
        """ç†æƒ³çš„ãªå¯¾è©±ã‚·ãƒŠãƒªã‚ªã‚’ç¶™ç¶š"""
        session_state = self._ideal_dialogue_sessions.get(session_id)
        if not session_state:
            return {
                "type": "error",
                "message": "å¯¾è©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            }
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã‚’è¨˜éŒ²ï¼ˆåˆå›ä»¥å¤–ï¼‰
        if user_response:
            session_state["user_responses"].append({
                "phase": session_state["phase"].value,
                "response": user_response,
                "timestamp": datetime.now().isoformat()
            })
        
        # ç¾åœ¨ã®ãƒ•ã‚§ãƒ¼ã‚ºãŒå®Œäº†ã‹ãƒã‚§ãƒƒã‚¯
        if session_state["phase"] == DialoguePhase.COMPLETED:
            # æœ€çµ‚çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ
            action_plan = await self._generate_final_action_plan(session_state)
            return {
                "type": "action_plan_completed",
                "action_plan": action_plan,
                "session_summary": self._create_session_summary(session_state)
            }
        
        # æ¬¡ã®ãƒ•ã‚§ãƒ¼ã‚ºã«é€²ã‚€ã‹ãƒã‚§ãƒƒã‚¯
        next_phase = self.ideal_dialogue_manager.determine_next_phase(
            session_state["phase"],
            session_state["user_responses"]
        )
        
        if next_phase != session_state["phase"]:
            session_state["phase"] = next_phase
            
            # ãƒ•ã‚§ãƒ¼ã‚ºå®Œäº†æ™‚ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            if user_response:
                phase_feedback = self._get_phase_completion_feedback(session_state["phase"])
                if phase_feedback:
                    return {
                        "type": "phase_transition",
                        "message": phase_feedback,
                        "current_phase": session_state["phase"].value,
                        "phase_description": self._get_phase_description(session_state["phase"])
                    }
        
        # ã‚½ã‚¯ãƒ©ãƒ†ã‚¹å¼è³ªå•ã‚’ç”Ÿæˆ
        try:
            socratic_response = await self.ideal_dialogue_manager.get_socratic_question(
                session_state["phase"],
                session_state["context"],
                session_state["user_responses"]
            )
            
            return {
                "type": "socratic_question",
                "question": socratic_response.question,
                "purpose": socratic_response.purpose,
                "expected_insight": socratic_response.expected_insight,
                "phase": socratic_response.phase,
                "next_phase_condition": socratic_response.next_phase_condition,
                "phase_description": self._get_phase_description(session_state["phase"]),
                "progress": self._calculate_progress(session_state)
            }
            
        except Exception as e:
            return {
                "type": "error",
                "message": f"è³ªå•ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            }
    
    def _get_phase_description(self, phase: DialoguePhase) -> str:
        """ãƒ•ã‚§ãƒ¼ã‚ºã®èª¬æ˜ã‚’å–å¾—"""
        descriptions = {
            DialoguePhase.CURRENT_SITUATION: "ğŸ“‹ ç¾çŠ¶æŠŠæ¡ - ç¾åœ¨ã®çŠ¶æ³ã¨èª²é¡Œã‚’ç†è§£ã—ã¾ã™",
            DialoguePhase.PROBLEM_ANALYSIS: "ğŸ” èª²é¡Œåˆ†æ - æˆåŠŸä½“é¨“ã‚’ç™ºè¦‹ã—ã€å•é¡Œã‚’æ·±æ˜ã‚Šã—ã¾ã™",
            DialoguePhase.SOLUTION_EXPLORATION: "ğŸ’¡ è§£æ±ºç­–æ¢ç´¢ - æˆ¦ç•¥çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒæ–¹æ³•ã‚’è€ƒãˆã¾ã™",
            DialoguePhase.ACTION_PLAN: "ğŸ¯ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ - å…·ä½“çš„ã§æ¸¬å®šå¯èƒ½ãªç›®æ¨™ã‚’è¨­å®šã—ã¾ã™",
            DialoguePhase.EXECUTION_SUPPORT: "ğŸš€ å®Ÿè¡Œæ”¯æ´ - å®Ÿç¾å¯èƒ½æ€§ã¨ç¶™ç¶šã®ãŸã‚ã®ä»•çµ„ã¿ã‚’ä½œã‚Šã¾ã™",
            DialoguePhase.COMPLETED: "âœ… å®Œäº† - ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ãŒå®Œæˆã—ã¾ã—ãŸ"
        }
        return descriptions.get(phase, "å¯¾è©±ä¸­")
    
    def _get_phase_completion_feedback(self, completed_phase: DialoguePhase) -> Optional[str]:
        """ãƒ•ã‚§ãƒ¼ã‚ºå®Œäº†æ™‚ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"""
        feedbacks = {
            DialoguePhase.CURRENT_SITUATION: "ç¾çŠ¶ã‚’æ•´ç†ã§ãã¾ã—ãŸï¼æ¬¡ã«æˆåŠŸä½“é¨“ã‚’æ´»ç”¨ã™ã‚‹æ–¹æ³•ã‚’è€ƒãˆã¾ã—ã‚‡ã†ã€‚",
            DialoguePhase.PROBLEM_ANALYSIS: "ç´ æ™´ã‚‰ã—ã„æ°—ã¥ãã§ã™ã­ï¼ã“ã®æˆåŠŸä½“é¨“ã‚’ä»–ã®å ´é¢ã§ã‚‚æ´»ç”¨ã—ã¦ã„ãã¾ã—ã‚‡ã†ã€‚",
            DialoguePhase.SOLUTION_EXPLORATION: "æˆ¦ç•¥çš„ãªè¦–ç‚¹ãŒèº«ã«ã¤ã„ã¦ãã¾ã—ãŸï¼å…·ä½“çš„ãªè¡Œå‹•è¨ˆç”»ã«è½ã¨ã—è¾¼ã‚“ã§ã„ãã¾ã—ã‚‡ã†ã€‚",
            DialoguePhase.ACTION_PLAN: "å®Ÿè¡Œå¯èƒ½ãªè¨ˆç”»ãŒã§ãã¾ã—ãŸï¼æœ€å¾Œã«ç¶™ç¶šã™ã‚‹ãŸã‚ã®ä»•çµ„ã¿ã‚’è€ƒãˆã¾ã—ã‚‡ã†ã€‚",
            DialoguePhase.EXECUTION_SUPPORT: "å®Œç’§ã§ã™ï¼å®Ÿè¡Œã«å‘ã‘ãŸæº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚"
        }
        return feedbacks.get(completed_phase)
    
    def _calculate_progress(self, session_state: Dict[str, Any]) -> Dict[str, Any]:
        """é€²æ—ã‚’è¨ˆç®—"""
        phase_order = [
            DialoguePhase.CURRENT_SITUATION,
            DialoguePhase.PROBLEM_ANALYSIS,
            DialoguePhase.SOLUTION_EXPLORATION,
            DialoguePhase.ACTION_PLAN,
            DialoguePhase.EXECUTION_SUPPORT,
            DialoguePhase.COMPLETED
        ]
        
        current_index = phase_order.index(session_state["phase"])
        total_phases = len(phase_order) - 1  # COMPLETEDã‚’é™¤ã
        progress_percentage = int((current_index / total_phases) * 100)
        
        return {
            "current_phase_index": current_index,
            "total_phases": total_phases,
            "percentage": progress_percentage,
            "responses_in_current_phase": len([
                r for r in session_state["user_responses"] 
                if r.get("phase") == session_state["phase"].value
            ])
        }
    
    async def _generate_final_action_plan(self, session_state: Dict[str, Any]) -> Dict[str, Any]:
        """æœ€çµ‚çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", """
ã‚ãªãŸã¯æ–°äººå–¶æ¥­ãƒãƒ³ã®æˆé•·ã‚’æ”¯æ´ã™ã‚‹AIã‚³ãƒ¼ãƒã§ã™ã€‚

ä»¥ä¸‹ã®å¯¾è©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å†…å®¹ã‹ã‚‰ã€éƒ¨ä¸‹ã®æˆé•·ã‚’ä¿ƒã™åŒ…æ‹¬çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ä¸Šå¸ã®æŒ‡ç¤º: {abstract_instruction}
å¯¾è©±ã®è¨˜éŒ²: {dialogue_history}

ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ä½œæˆã®åŸå‰‡ã€‘
1. SMARTç›®æ¨™ï¼ˆå…·ä½“çš„ã€æ¸¬å®šå¯èƒ½ã€é”æˆå¯èƒ½ã€é–¢é€£æ€§ã€æœŸé™ä»˜ãï¼‰
2. æ®µéšçš„ãªå®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—
3. æˆåŠŸæŒ‡æ¨™ã¨æ¸¬å®šæ–¹æ³•
4. äºˆæƒ³ã•ã‚Œã‚‹éšœå®³ã¨å¯¾ç­–
5. ç¶™ç¶šçš„ãªæˆé•·ã®ãŸã‚ã®ä»•çµ„ã¿
6. å®šæœŸçš„ãªæŒ¯ã‚Šè¿”ã‚Šãƒã‚¤ãƒ³ãƒˆ

JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
    "summary": "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã®æ¦‚è¦",
    "smart_goals": [
        {{
            "goal": "å…·ä½“çš„ãªç›®æ¨™",
            "specific": "å…·ä½“çš„ãªå†…å®¹",
            "measurable": "æ¸¬å®šæŒ‡æ¨™",
            "achievable": "é”æˆå¯èƒ½æ€§",
            "relevant": "é–¢é€£æ€§",
            "time_bound": "æœŸé™"
        }}
    ],
    "action_steps": [
        {{
            "step": "ã‚¹ãƒ†ãƒƒãƒ—ç•ªå·",
            "action": "å…·ä½“çš„ãªè¡Œå‹•",
            "deadline": "æœŸé™",
            "success_criteria": "æˆåŠŸåŸºæº–"
        }}
    ],
    "success_metrics": {{
        "quantitative": ["å®šé‡çš„æŒ‡æ¨™"],
        "qualitative": ["å®šæ€§çš„æŒ‡æ¨™"]
    }},
    "potential_obstacles": [
        {{
            "obstacle": "äºˆæƒ³ã•ã‚Œã‚‹éšœå®³",
            "solution": "è§£æ±ºç­–"
        }}
    ],
    "continuous_improvement": {{
        "weekly_check": "é€±æ¬¡ãƒã‚§ãƒƒã‚¯é …ç›®",
        "monthly_review": "æœˆæ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼é …ç›®",
        "quarterly_goal": "å››åŠæœŸç›®æ¨™"
    }}
}}
"""),
            ("user", "å¯¾è©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        ])
        
        chain = (
            {
                "abstract_instruction": lambda _: session_state["abstract_instruction"],
                "dialogue_history": lambda _: json.dumps(session_state["user_responses"], ensure_ascii=False)
            }
            | prompt
            | self.llm
        )
        
        try:
            response = await chain.ainvoke({})
            action_plan_text = response.content
            
            # JSONãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œ
            import re
            json_match = re.search(r'\{.*\}', action_plan_text, re.DOTALL)
            if json_match:
                action_plan = json.loads(json_match.group())
            else:
                # JSONãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãã®ã¾ã¾ã‚’è¿”ã™
                action_plan = {"raw_response": action_plan_text}
                
            return action_plan
            
        except Exception as e:
            return {
                "error": f"ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                "raw_dialogue": session_state["user_responses"]
            }
    
    def _create_session_summary(self, session_state: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è¦ç´„ã‚’ä½œæˆ"""
        return {
            "abstract_instruction": session_state["abstract_instruction"],
            "total_responses": len(session_state["user_responses"]),
            "phases_completed": len(set(r.get("phase") for r in session_state["user_responses"])),
            "duration": session_state.get("started_at"),
            "final_phase": session_state["phase"].value
        }

    async def process_user_response(
        self,
        session_id: str,
        user_response: str,
        db_session: Any
    ) -> Dict[str, Any]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã‚’å‡¦ç†"""
        # ãƒ¡ãƒ¢ãƒªã«å›ç­”ã‚’è¿½åŠ 
        await self.memory_service.add_message(
            session_id=session_id,
            role="user",
            content=user_response,
            db=db_session
        )
        
        # 1on1ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®å†…å®¹ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        is_one_on_one = self._is_one_on_one_content(user_response)
        
        if is_one_on_one:
            # 1on1ã®å ´åˆã¯å¯¾è©±å‹å…·ä½“åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹
            user_id = session_id.replace("slack_", "")
            
            try:
                # 1on1ã®åˆæœŸåˆ†æã‚’å®Ÿè¡Œï¼ˆä¸Šå¸ã®æŒ‡ç¤ºç‰¹å®šã®ã¿ï¼‰
                abstract_instructions = await self._extract_supervisor_instructions_from_one_on_one(
                    user_response, db_session
                )
                
                # å¯¾è©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çŠ¶æ…‹ã‚’ä¿å­˜
                await self._save_one_on_one_session_state(
                    session_id, 
                    user_response, 
                    abstract_instructions,
                    db_session
                )
                
                # æœ€åˆã®æ·±æ˜ã‚Šè³ªå•ã‚’ç”Ÿæˆ
                first_questions = await self._generate_initial_clarification_questions(
                    abstract_instructions[0] if abstract_instructions else None,
                    user_response
                )
                
                return {
                    "type": "one_on_one_clarification",
                    "questions": first_questions,
                    "instruction_being_clarified": abstract_instructions[0] if abstract_instructions else None,
                    "total_instructions": len(abstract_instructions),
                    "current_instruction_index": 0,
                    "stage": "instruction_clarification",
                    "stage_description": f"ğŸ“‹ ä¸Šå¸ã®æŒ‡ç¤ºã®å…·ä½“åŒ– (1/{len(abstract_instructions)})"
                }
                
            except Exception as e:
                return {
                    "type": "error", 
                    "message": f"1on1åˆ†æé–‹å§‹ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                }
        else:
            # 1on1ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶™ç¶šä¸­ã‹ãƒã‚§ãƒƒã‚¯
            one_on_one_session = await self._get_one_on_one_session_state(session_id)
            
            if one_on_one_session:
                # 1on1ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶™ç¶šä¸­ - æ·±æ˜ã‚Šè³ªå•ã¸ã®å›ç­”ã‚’å‡¦ç†
                try:
                    return await self._continue_one_on_one_clarification(
                        session_id, 
                        user_response, 
                        one_on_one_session,
                        db_session
                    )
                except Exception as e:
                    return {
                        "type": "error",
                        "message": f"1on1ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶™ç¶šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                    }
            
            # å¾“æ¥ã®è³ªå•ãƒ™ãƒ¼ã‚¹ã®å¯¾è©±
            context = await self.memory_service.get_conversation_context(
                session_id=session_id,
                include_summary=True
            )
            
            completeness_score = await self._evaluate_completeness(context)
            
            if completeness_score >= 80:
                action_plan = await self._generate_action_plan(context)
                return {
                    "type": "action_plan",
                    "data": action_plan,
                    "completeness_score": completeness_score
                }
            else:
                follow_up_questions = await self._generate_follow_up_questions(context)
                return {
                    "type": "follow_up",
                    "questions": follow_up_questions,
                    "completeness_score": completeness_score
                }
    
    def _is_one_on_one_content(self, content: str) -> bool:
        """1on1ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®å†…å®¹ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        
        # 1on1ã®ç‰¹å¾´çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        one_on_one_indicators = [
            # åŸºæœ¬çš„ãªå¯¾è©±å½¢å¼
            "ï¼š" in content and content.count("ï¼š") >= 2,  # è¤‡æ•°ã®è©±è€…
            len(content) > 100,  # é•·ã‚ã®å†…å®¹
            
            # å–¶æ¥­æ´»å‹•é–¢é€£
            "è·é›¢ã‚’è©°ã‚ã‚‹" in content,
            "ä¿¡é ¼é–¢ä¿‚" in content,
            "æ¸©åº¦æ„Ÿ" in content,
            "èª²é¡Œã«å¯„ã‚Šæ·»ã£ãŸ" in content,
            "å–¶æ¥­æ´»å‹•" in content and "èª¿å­" in content,
            "æ–°è¦ã‚¢ãƒ" in content,
            "æˆç´„" in content,
            
            # ä¸Šå¸ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ»æŒ‡å°ãƒ‘ã‚¿ãƒ¼ãƒ³
            "ã‚‚ã†å°‘ã—" in content and ("ã¨ã„ã„ã­" in content or "ã¨ã„ã„ã‹ãª" in content),
            "ãŒã‚«ã‚®ã ã¨æ€ã†" in content,
            "ã‚’æ„è­˜ã—ã¦" in content,
            "æ„Ÿè¦šã‚’ç£¨ã„ã¦" in content or "æ•°ã“ãªã—ã¦" in content,
            
            # ææ¡ˆè³‡æ–™ãƒ»æˆæœç‰©ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            "ææ¡ˆè³‡æ–™" in content,
            "ä¼ã‚ã‚‹è³‡æ–™" in content or "ã‚ã‹ã‚Šã‚„ã™ã" in content,
            "ã‚¹ãƒˆãƒ¼ãƒªãƒ¼æ€§" in content,
            "ã‚»ãƒ³ã‚¹" in content and ("è³‡æ–™" in content or "ææ¡ˆ" in content),
            "ç©ºæ°—æ„Ÿ" in content,
            "æ´—ç·´" in content,
            
            # ä¸€èˆ¬çš„ãªä¸Šå¸ãƒ»éƒ¨ä¸‹ã®å¯¾è©±ãƒ‘ã‚¿ãƒ¼ãƒ³
            "ç¢ºèªã—ãŸã‚ˆ" in content or "ç¢ºèªã—ã¾ã—ãŸ" in content,
            "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯" in content,
            "ã‚‚ã†ä¸€æ­©" in content,
            "æ”¹å–„" in content and ("ã§ãã‚‹" in content or "ã—ã¦ã„ã“ã†" in content),
            "é ‘å¼µã‚Šã¾ã™" in content and ("åˆ†ã‹ã‚Šã¾ã—ãŸ" in content or "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™" in content),
            
            # æŠ½è±¡çš„ãªæŒ‡ç¤ºãƒ‘ã‚¿ãƒ¼ãƒ³
            "æ›–æ˜§" in content or "æŠ½è±¡çš„" in content,
            "å…·ä½“çš„ã«" in content and "ã©ã†" in content,
            "ä¾‹ãˆã°" in content and "ã©ã“ã‚’" in content,
            
            # æ€è€ƒã‚„å†…å¿ƒã®æå†™ï¼ˆ1on1ãƒ­ã‚°ã®ç‰¹å¾´ï¼‰
            "ï¼ˆ" in content and "ï¼‰" in content and content.count("ï¼ˆ") >= 2
        ]
        
        # è¤‡æ•°ã®æŒ‡æ¨™ãŒå½“ã¦ã¯ã¾ã‚‹å ´åˆã¯1on1ã¨åˆ¤å®šï¼ˆé–¾å€¤ã‚’2ã«ä¸‹ã’ã‚‹ï¼‰
        matching_indicators = sum(1 for indicator in one_on_one_indicators if indicator)
        return matching_indicators >= 2
    
    def _determine_dialogue_stage(self, context: Dict[str, Any], completeness_score: int) -> str:
        """å¯¾è©±ã®æ®µéšã‚’åˆ¤å®š"""
        messages = context.get("messages", [])
        message_count = len([msg for msg in messages if msg.get("role") == "user"])
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ã¨å®Œäº†åº¦ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹æ®µéšåˆ¤å®š
        if message_count <= 1:
            return "initial_understanding"  # åˆæœŸç†è§£æ®µéš
        elif message_count <= 3 and completeness_score < 40:
            return "problem_clarification"  # èª²é¡Œæ˜ç¢ºåŒ–æ®µéš  
        elif message_count <= 5 and completeness_score < 70:
            return "deep_analysis"  # æ·±ã„åˆ†ææ®µéš
        elif completeness_score < 85:
            return "solution_exploration"  # è§£æ±ºç­–æ¢ç´¢æ®µéš
        elif completeness_score < 95:
            return "action_preparation"  # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æº–å‚™æ®µéš
        else:
            return "action_plan"  # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆæ®µéš
    
    def _get_stage_description(self, stage: str) -> str:
        """æ®µéšã®èª¬æ˜ã‚’å–å¾—"""
        descriptions = {
            "initial_understanding": "ğŸ“‹ åˆæœŸçŠ¶æ³ã®ç†è§£",
            "problem_clarification": "ğŸ¯ èª²é¡Œã®æ˜ç¢ºåŒ–", 
            "deep_analysis": "ğŸ” è©³ç´°åˆ†æ",
            "solution_exploration": "ğŸ’¡ è§£æ±ºç­–ã®æ¢ç´¢",
            "action_preparation": "ğŸ“ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æº–å‚™",
            "action_plan": "ğŸš€ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆ"
        }
        return descriptions.get(stage, "ğŸ¤” åˆ†æä¸­")
    
    async def _generate_stage_based_questions(self, context: Dict[str, Any], stage: str) -> List[str]:
        """æ®µéšã«åŸºã¥ã„ãŸè³ªå•ç”Ÿæˆ"""
        if stage == "initial_understanding":
            return await self._generate_initial_questions(context)
        elif stage == "problem_clarification":
            return await self._generate_clarification_questions(context)
        elif stage == "deep_analysis":
            return await self._generate_analysis_questions(context)
        elif stage == "solution_exploration":
            return await self._generate_solution_questions(context)
        elif stage == "action_preparation":
            return await self._generate_preparation_questions(context)
        else:
            return await self._generate_follow_up_questions(context)
    
    async def _generate_initial_questions(self, context: Dict[str, Any]) -> List[str]:
        """åˆæœŸç†è§£ã®ãŸã‚ã®è³ªå•ç”Ÿæˆ"""
        messages = context.get("messages", [])
        latest_message = messages[-1].get("content", "") if messages else ""
        
        # 1on1ã®å†…å®¹ã‹ã‚‰æŠ½è±¡çš„ãªæŒ‡ç¤ºã‚’ç‰¹å®š
        if "è·é›¢ã‚’è©°ã‚ã‚‹" in latest_message or "ä¿¡é ¼é–¢ä¿‚" in latest_message:
            return [
                "ä¸Šå¸ã‹ã‚‰ã€Œé¡§å®¢ã¨ã®è·é›¢ã‚’è©°ã‚ã‚‹ã€ã¨ã„ã†æŒ‡æ‘˜ãŒã‚ã‚Šã¾ã—ãŸãŒã€å…·ä½“çš„ã«ã©ã®ã‚ˆã†ãªå ´é¢ã§ãã†æ„Ÿã˜ã‚‰ã‚ŒãŸã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ",
                "ã“ã‚Œã¾ã§ã®å–¶æ¥­æ´»å‹•ã§ã€é¡§å®¢ã¨ã®é–¢ä¿‚æ§‹ç¯‰ã«ãŠã„ã¦æœ€ã‚‚å›°é›£ã ã£ãŸç¬é–“ã¯ã©ã‚“ãªæ™‚ã§ã—ãŸã‹ï¼Ÿ",
                "ç¾åœ¨ã€æ–°è¦é¡§å®¢ã¨ã®ã‚„ã‚Šå–ã‚Šã§ç‰¹ã«æ„è­˜ã—ã¦ã„ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"
            ]
        elif "ç›¸æ‰‹ã®èª²é¡Œã«å¯„ã‚Šæ·»ã£ãŸææ¡ˆ" in latest_message:
            return [
                "ã€Œç›¸æ‰‹ã®èª²é¡Œã«å¯„ã‚Šæ·»ã£ãŸææ¡ˆã€ã«ã¤ã„ã¦ã€ã“ã‚Œã¾ã§ã©ã®ã‚ˆã†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å–ã‚‰ã‚Œã¦ã„ã¾ã—ãŸã‹ï¼Ÿ",
                "é¡§å®¢ã®ãƒ’ã‚¢ãƒªãƒ³ã‚°æ™‚ã«ã€ã©ã‚“ãªè³ªå•ã‚’ã™ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã‹ï¼Ÿ",
                "ææ¡ˆå†…å®¹ã‚’æ±ºã‚ã‚‹éš›ã«ã€æœ€ã‚‚é‡è¦–ã—ã¦ã„ã‚‹ç‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿ"
            ]
        elif "æ¸©åº¦æ„Ÿã‚’èª­ã‚€" in latest_message:
            return [
                "ä¸Šå¸ã‹ã‚‰ã€Œé¡§å®¢ã®æ¸©åº¦æ„Ÿã‚’èª­ã‚€ã€ã¨ã„ã†æŒ‡æ‘˜ãŒã‚ã‚Šã¾ã—ãŸãŒã€ã“ã‚Œã¾ã§ã«ãã†ã„ã£ãŸæ„Ÿè¦šã‚’æ„è­˜ã—ãŸã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                "å•†è«‡ä¸­ã«ã€é¡§å®¢ã®èˆˆå‘³ã‚„é–¢å¿ƒåº¦ã‚’ã©ã®ã‚ˆã†ã«åˆ¤æ–­ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ",
                "é¡§å®¢ãŒç©æ¥µçš„ãªæ™‚ã¨æ¶ˆæ¥µçš„ãªæ™‚ã®é•ã„ã‚’ã€ä½•ã§æ„Ÿã˜å–ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã‹ï¼Ÿ"
            ]
        else:
            return [
                "ã“ã®1on1ã®å†…å®¹ã«ã¤ã„ã¦ã€ã©ã®éƒ¨åˆ†ãŒæœ€ã‚‚æ”¹å–„ã—ãŸã„ãƒã‚¤ãƒ³ãƒˆã ã¨æ„Ÿã˜ã¾ã™ã‹ï¼Ÿ",
                "ä¸Šå¸ã‹ã‚‰ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã§ã€ç‰¹ã«å…·ä½“çš„ãªæ–¹æ³•ã‚’çŸ¥ã‚ŠãŸã„ã¨æ€ã£ãŸéƒ¨åˆ†ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                "ç¾åœ¨ã®å–¶æ¥­æ´»å‹•ã§ã€æœ€ã‚‚ä¸å®‰ã«æ„Ÿã˜ã¦ã„ã‚‹ã“ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ"
            ]
    
    async def _generate_clarification_questions(self, context: Dict[str, Any]) -> List[str]:
        """èª²é¡Œæ˜ç¢ºåŒ–ã®ãŸã‚ã®è³ªå•ç”Ÿæˆ"""
        return [
            "ãã®èª²é¡ŒãŒç™ºç”Ÿã™ã‚‹å…¸å‹çš„ãªã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å…·ä½“çš„ã«æ•™ãˆã¦ãã ã•ã„",
            "åŒã˜ã‚ˆã†ãªçŠ¶æ³ã§ã€ã†ã¾ãã„ã£ãŸçµŒé¨“ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿãã®æ™‚ã¯ä½•ãŒé•ã„ã¾ã—ãŸã‹ï¼Ÿ",
            "ã“ã®èª²é¡Œã«ã‚ˆã£ã¦ã€å®Ÿéš›ã«ã©ã®ã‚ˆã†ãªæå¤±ã‚„æ©Ÿä¼šæå¤±ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã‹ï¼Ÿ"
        ]
    
    async def _generate_analysis_questions(self, context: Dict[str, Any]) -> List[str]:
        """æ·±ã„åˆ†æã®ãŸã‚ã®è³ªå•ç”Ÿæˆ"""
        return [
            "ãã®èª²é¡Œã®æ ¹æœ¬çš„ãªåŸå› ã¯ä½•ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ",
            "ã“ã‚Œã¾ã§ã«è©¦ã—ãŸã“ã¨ãŒã‚ã‚‹è§£æ±ºç­–ãŒã‚ã‚Œã°æ•™ãˆã¦ãã ã•ã„",
            "ç†æƒ³çš„ãªçŠ¶æ…‹ã«ãªã£ãŸã¨ãã€ã©ã®ã‚ˆã†ãªå¤‰åŒ–ãŒæœŸå¾…ã§ãã¾ã™ã‹ï¼Ÿ"
        ]
    
    async def _generate_solution_questions(self, context: Dict[str, Any]) -> List[str]:
        """è§£æ±ºç­–æ¢ç´¢ã®ãŸã‚ã®è³ªå•ç”Ÿæˆ"""
        return [
            "è§£æ±ºç­–ã‚’å®Ÿè¡Œã™ã‚‹ä¸Šã§ã€ã©ã®ã‚ˆã†ãªã‚µãƒãƒ¼ãƒˆã‚„è³‡æºãŒå¿…è¦ã§ã™ã‹ï¼Ÿ",
            "ã“ã®æ”¹å–„ã«å–ã‚Šçµ„ã‚€éš›ã®æœŸé™ã‚„ç›®æ¨™ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            "æˆåŠŸã‚’æ¸¬ã‚‹å…·ä½“çš„ãªæŒ‡æ¨™ãŒã‚ã‚Œã°æ•™ãˆã¦ãã ã•ã„"
        ]
    
    async def _generate_preparation_questions(self, context: Dict[str, Any]) -> List[str]:
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æº–å‚™ã®ãŸã‚ã®è³ªå•ç”Ÿæˆ"""
        return [
            "å®Ÿè¡Œã«ç§»ã™å‰ã«ä¸å®‰ãªç‚¹ã‚„æ‡¸å¿µã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            "å–ã‚Šçµ„ã¿ã‚’å§‹ã‚ã‚‹æœ€é©ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¯ã„ã¤é ƒã§ã—ã‚‡ã†ã‹ï¼Ÿ",
            "é€²æ—ã‚’ç¢ºèªã™ã‚‹æ–¹æ³•ã‚„é »åº¦ã¯ã©ã†ã—ã¾ã™ã‹ï¼Ÿ"
        ]
    
    async def _evaluate_completeness(self, context: Dict[str, Any]) -> int:
        """æƒ…å ±ã®å……è¶³åº¦ã‚’è©•ä¾¡"""
        context_str = json.dumps(context, ensure_ascii=False, indent=2)
        messages = [
            {"role": "system", "content": """å–¶æ¥­ã‚¹ã‚­ãƒ«å‘ä¸Šã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ä½œæˆã«å¿…è¦ãªæƒ…å ±ã®å……è¶³åº¦ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

æ®µéšçš„è©•ä¾¡åŸºæº–ï¼š
ã€20-30ç‚¹ã€‘èª²é¡Œã®æ¦‚è¦ã¯ç†è§£ã§ãã‚‹ãŒã€å…·ä½“æ€§ã«æ¬ ã‘ã‚‹
ã€40-50ç‚¹ã€‘èª²é¡Œã¯æ˜ç¢ºã ãŒã€å…·ä½“çš„ãªçŠ¶æ³ã‚„èƒŒæ™¯æƒ…å ±ãŒä¸è¶³
ã€60-70ç‚¹ã€‘èª²é¡Œã¨çŠ¶æ³ã¯æ˜ç¢ºã ãŒã€è©³ç´°ãªåˆ†æãŒå¿…è¦
ã€80-85ç‚¹ã€‘è©³ç´°ã¯æƒã£ã¦ã„ã‚‹ãŒã€è§£æ±ºç­–ã®æ–¹å‘æ€§ãŒæœªç¢ºå®š
ã€90-95ç‚¹ã€‘å…¨ã¦ã®æƒ…å ±ãŒæƒã„ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ä½œæˆæº–å‚™å®Œäº†
ã€95ç‚¹ä»¥ä¸Šã€‘ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆã«ååˆ†ãªæƒ…å ±

ä»¥ä¸‹ã®è¦³ç‚¹ã§å³æ ¼ã«è©•ä¾¡ã—ã¦ãã ã•ã„ï¼š
1. èª²é¡Œã®å…·ä½“æ€§ï¼ˆæŠ½è±¡çš„ãªæŒ‡æ‘˜â†’å…·ä½“çš„ãªå ´é¢ï¼‰
2. æ ¹æœ¬åŸå› ã®æŠŠæ¡ï¼ˆç—‡çŠ¶â†’åŸå› ã®ç‰¹å®šï¼‰
3. ç›®æ¨™ã¨æœŸé™ã®æ˜ç¢ºåŒ–
4. å®Ÿè¡Œå¯èƒ½æ€§ã®æ¤œè¨¼
5. æˆåŠŸæŒ‡æ¨™ã®å®šç¾©

0-100ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚æ•°å­—ã®ã¿å›ç­”ã—ã¦ãã ã•ã„ã€‚"""},
            {"role": "user", "content": f"ä¼šè©±å±¥æ­´ï¼š\n{context_str}\n\nå……è¶³åº¦ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰:"}
        ]
        
        from langchain.schema import HumanMessage, SystemMessage
        langchain_messages = [
            SystemMessage(content=messages[0]["content"]),
            HumanMessage(content=messages[1]["content"])
        ]
        response = await self.llm.ainvoke(langchain_messages)
        try:
            score = int(response.content.strip())
            return min(max(score, 0), 100)  # 0-100ã®ç¯„å›²ã«åˆ¶é™
        except:
            return 50  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    async def _generate_follow_up_questions(
        self,
        context: Dict[str, Any]
    ) -> List[str]:
        """ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—è³ªå•ã‚’ç”Ÿæˆ"""
        # ãƒ¡ãƒ¢ãƒªã‹ã‚‰å±¥æ­´ã‚’å–å¾—
        memory = await self.memory_service.get_or_create_memory(context["session_id"])
        messages = memory.chat_memory.messages
        
        # ä¼šè©±å±¥æ­´ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        chat_history = "\n".join([
            f"{msg.type}: {msg.content}" for msg in messages[-5:]  # æœ€æ–°5ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        ])
        
        prompt_messages = [
            {"role": "system", "content": """ã“ã‚Œã¾ã§ã®ä¼šè©±å†…å®¹ã‚’è¸ã¾ãˆã¦ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ä½œæˆã«å¿…è¦ãªè¿½åŠ æƒ…å ±ã‚’åé›†ã™ã‚‹ãŸã‚ã®è³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
            
            ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼š
            1. ã™ã§ã«å¾—ã‚‰ã‚ŒãŸæƒ…å ±ã‚’è¸ã¾ãˆã¦ã€ã‚ˆã‚Šå…·ä½“çš„ãªè³ªå•ã‚’ã™ã‚‹
            2. å®Ÿè·µçš„ã§æ¸¬å®šå¯èƒ½ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ã¤ãªãŒã‚‹æƒ…å ±ã‚’åé›†ã™ã‚‹
            3. å–¶æ¥­ã‚¹ã‚­ãƒ«å‘ä¸Šã«ç›´æ¥é–¢é€£ã™ã‚‹è³ªå•ã‚’ã™ã‚‹
            
            è³ªå•ã¯1è¡Œãšã¤ã€ŒQ: ã€ã§å§‹ã‚ã¦3-5å€‹å›ç­”ã—ã¦ãã ã•ã„ã€‚"""},
            {"role": "user", "content": f"ä¼šè©±å±¥æ­´ï¼š\n{chat_history}\n\nè¿½åŠ ã§å¿…è¦ãªæƒ…å ±ã‚’åé›†ã™ã‚‹ãŸã‚ã®è³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"}
        ]
        
        langchain_messages = [
            SystemMessage(content=prompt_messages[0]["content"]),
            HumanMessage(content=prompt_messages[1]["content"])
        ]
        response = await self.llm.ainvoke(langchain_messages)
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰è³ªå•ã‚’æŠ½å‡º
        questions = []
        for line in response.content.split('\n'):
            line = line.strip()
            if line.startswith('Q:'):
                questions.append(line[2:].strip())
            elif line.startswith('è³ªå•'):
                questions.append(line.split(':', 1)[-1].strip())
        
        # æœ€ä½1ã¤ã®è³ªå•ã‚’ä¿è¨¼
        if not questions:
            questions = ["ã“ã‚Œã¾ã§ã®å†…å®¹ã«ã¤ã„ã¦ã€ã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ"]
        
        return questions[:5]  # æœ€å¤§5å€‹ã¾ã§
    
    async def _generate_action_plan(
        self,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä¼šè©±å†…å®¹ã‚’åŸºã«ã€æ–°äººå–¶æ¥­ãƒãƒ³ã®æˆé•·ã®ãŸã‚ã®
            å…·ä½“çš„ã§å®Ÿè¡Œå¯èƒ½ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
            
            ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
            1. å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ï¼ˆå„ªå…ˆé †ä½ä»˜ãï¼‰
            2. å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æœŸé™ã¨æˆåŠŸæŒ‡æ¨™
            3. å¿…è¦ãªãƒªã‚½ãƒ¼ã‚¹ã‚„ã‚µãƒãƒ¼ãƒˆ
            4. æœŸå¾…ã•ã‚Œã‚‹æˆæœ
            
            {format_instructions}
            """),
            MessagesPlaceholder(variable_name="chat_history"),
            ("user", "ã“ã‚Œã¾ã§ã®ä¼šè©±å†…å®¹ã‚’åŸºã«ã€æˆé•·æ”¯æ´ã®ãŸã‚ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        ])
        
        memory = await self.memory_service.get_or_create_memory(context["session_id"])
        messages = memory.chat_memory.messages
        
        chain = (
            {
                "chat_history": lambda _: messages,
                "format_instructions": lambda _: self.action_plan_parser.get_format_instructions()
            }
            | prompt
            | self.llm
            | self.action_plan_parser
        )
        
        response = await chain.ainvoke({})
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
        return {
            "action_items": response.action_items,
            "summary": response.summary,
            "key_improvements": response.key_improvements,
            "metrics": response.metrics,
            "generated_at": datetime.utcnow().isoformat()
        }
    
    async def save_dialogue_state(
        self,
        session_id: str,
        state: str,
        metadata: Dict[str, Any],
        db_session: Any
    ) -> None:
        """å¯¾è©±ã®çŠ¶æ…‹ã‚’ä¿å­˜"""
        # Redisã«çŠ¶æ…‹ã‚’ä¿å­˜
        state_key = f"dialogue:state:{session_id}"
        state_data = {
            "state": state,
            "metadata": metadata,
            "updated_at": datetime.utcnow().isoformat()
        }
        
        if self.memory_service.redis_client:
            await self.memory_service.redis_client.setex(
                state_key,
                86400,  # 24æ™‚é–“
                json.dumps(state_data, ensure_ascii=False)
            )
    
    async def get_dialogue_state(
        self,
        session_id: str
    ) -> Optional[Dict[str, Any]]:
        """å¯¾è©±ã®çŠ¶æ…‹ã‚’å–å¾—"""
        if not self.memory_service.redis_client:
            return None
        
        state_key = f"dialogue:state:{session_id}"
        state_data = await self.memory_service.redis_client.get(state_key)
        
        if state_data:
            return json.loads(state_data)
        return None
    
    # === 1on1å¯¾è©±å‹å…·ä½“åŒ–ã‚·ã‚¹ãƒ†ãƒ  ===
    
    async def _extract_supervisor_instructions_from_one_on_one(
        self, 
        one_on_one_content: str, 
        db_session: Any
    ) -> List[Dict[str, str]]:
        """LLMã‚’ä½¿ã£ã¦1on1ã‹ã‚‰ä¸Šå¸ã®æŠ½è±¡çš„æŒ‡ç¤ºã‚’ç‰¹å®š"""
        
        prompt_messages = [
            SystemMessage(content="""1on1ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®å†…å®¹ã‹ã‚‰ã€ä¸Šå¸ãŒæ–°äººå–¶æ¥­ãƒãƒ³ã«å¯¾ã—ã¦å‡ºã—ãŸæŠ½è±¡çš„ãªæŒ‡ç¤ºã‚„æ”¹å–„ç‚¹ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®åŸºæº–ã§ã€ŒæŠ½è±¡çš„ãªæŒ‡ç¤ºã€ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ï¼š
- æ–°äººå–¶æ¥­ãƒãƒ³ãŒã€Œå…·ä½“çš„ã«ã©ã†ã™ã‚Œã°ã„ã„ã®ã‹ã‚ã‹ã‚‰ãªã„ã€ã¨æ„Ÿã˜ã‚‹ã‚ˆã†ãªæŒ‡ç¤º
- ã€Œã‚‚ã£ã¨ã€œã™ã‚‹ã€ã€Œã€œã‚’æ„è­˜ã™ã‚‹ã€ã€Œã€œã—ã¦ã„ã‘ã‚‹ã¨ã„ã„ã­ã€ã®ã‚ˆã†ãªè¡¨ç¾
- å…·ä½“çš„ãªè¡Œå‹•æ‰‹é †ãŒæ˜ç¢ºã§ãªã„æ”¹å–„ææ¡ˆ

é‡è¦: è³ªå•ç”Ÿæˆæ™‚ã®æ–‡è„ˆåˆ¶ç´„ã®ãŸã‚ã€æŒ‡ç¤ºã®å…·ä½“çš„ãªã‚¹ã‚³ãƒ¼ãƒ—ã¨å¢ƒç•Œã‚’æ˜ç¢ºã«å®šç¾©ã—ã¦ãã ã•ã„ã€‚

å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
```json
{
  "abstract_instructions": [
    {
      "original_text": "ä¸Šå¸ã®ç™ºè¨€ãã®ã¾ã¾",
      "abstract_concept": "æŠ½è±¡çš„ãªæ¦‚å¿µï¼ˆä¾‹ï¼šè·é›¢ã‚’è©°ã‚ã‚‹ã€ä¿¡é ¼é–¢ä¿‚æ§‹ç¯‰ã€ä¼ã‚ã‚‹è³‡æ–™ä½œæˆï¼‰",
      "specific_scope": "ã“ã®æŒ‡ç¤ºãŒå¯¾è±¡ã¨ã™ã‚‹å…·ä½“çš„ãªç¯„å›²ï¼ˆä¾‹ï¼šææ¡ˆè³‡æ–™ã®ä½œæˆæŠ€è¡“ã€é¡§å®¢ã¨ã®ä¼šè©±è¡“ï¼‰",
      "excluded_areas": ["ã“ã®æŒ‡ç¤ºã«å«ã¾ã‚Œãªã„é–¢é€£é ˜åŸŸ1", "å«ã¾ã‚Œãªã„é–¢é€£é ˜åŸŸ2"],
      "key_elements": ["æŒ‡ç¤ºã«å«ã¾ã‚Œã‚‹ä¸»è¦è¦ç´ 1", "ä¸»è¦è¦ç´ 2", "ä¸»è¦è¦ç´ 3"],
      "category": "ã‚«ãƒ†ã‚´ãƒªï¼ˆcustomer_relationship, trust_building, document_creationç­‰ï¼‰",
      "urgency": "å„ªå…ˆåº¦ï¼ˆhigh, medium, lowï¼‰"
    }
  ]
}
```"""),
            HumanMessage(content=f"ä»¥ä¸‹ã®1on1å†…å®¹ã‹ã‚‰æŠ½è±¡çš„ãªæŒ‡ç¤ºã‚’ç‰¹å®šã—ã€å„æŒ‡ç¤ºã®å…·ä½“çš„ãªã‚¹ã‚³ãƒ¼ãƒ—ã¨å¢ƒç•Œã‚’æ˜ç¢ºã«å®šç¾©ã—ã¦ãã ã•ã„ï¼š\n\n{one_on_one_content}")
        ]
        
        try:
            response = await self.llm.ainvoke(prompt_messages)
            response_text = response.content.strip()
            
            # JSONã‚’æŠ½å‡º
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                if json_end != -1:
                    response_text = response_text[json_start:json_end].strip()
            
            parsed_response = json.loads(response_text)
            return parsed_response.get("abstract_instructions", [])
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯åŸºæœ¬çš„ãªæŒ‡ç¤ºã‚’è¿”ã™
            return [{
                "original_text": "ä¸Šå¸ã‹ã‚‰ã®æ”¹å–„æŒ‡ç¤º",
                "abstract_concept": "å–¶æ¥­ã‚¹ã‚­ãƒ«å‘ä¸Š",
                "category": "general_improvement",
                "urgency": "medium"
            }]
    
    async def _save_one_on_one_session_state(
        self, 
        session_id: str, 
        original_content: str, 
        instructions: List[Dict[str, str]],
        db_session: Any
    ) -> None:
        """1on1ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çŠ¶æ…‹ã‚’ä¿å­˜"""
        
        state_data = {
            "type": "one_on_one_clarification",
            "original_content": original_content,
            "abstract_instructions": instructions,
            "current_instruction_index": 0,
            "clarified_instructions": [],  # å…·ä½“åŒ–ã•ã‚ŒãŸæŒ‡ç¤ºã‚’ä¿å­˜
            "conversation_history": [],  # å„æŒ‡ç¤ºã®å…·ä½“åŒ–å¯¾è©±å±¥æ­´
            "started_at": datetime.utcnow().isoformat()
        }
        
        # Redisã«ä¿å­˜ã‚’è©¦è¡Œã€å¤±æ•—ã—ãŸã‚‰ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã«ä¿å­˜
        if self.memory_service.redis_client:
            try:
                session_key = f"one_on_one_session:{session_id}"
                await self.memory_service.redis_client.setex(
                    session_key,
                    86400,  # 24æ™‚é–“
                    json.dumps(state_data, ensure_ascii=False)
                )
            except Exception:
                # Redisã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                self._in_memory_sessions[session_id] = state_data
        else:
            # RedisãŒãªã„å ´åˆã¯ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã«ä¿å­˜
            self._in_memory_sessions[session_id] = state_data
    
    async def _get_one_on_one_session_state(self, session_id: str) -> Optional[Dict[str, Any]]:
        """1on1ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çŠ¶æ…‹ã‚’å–å¾—"""
        
        # ã¾ãšRedisã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ
        if self.memory_service.redis_client:
            try:
                session_key = f"one_on_one_session:{session_id}"
                state_data = await self.memory_service.redis_client.get(session_key)
                if state_data:
                    return json.loads(state_data)
            except Exception:
                pass  # Redisã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‹ã‚‰å–å¾—
        
        # RedisãŒãªã„å ´åˆã‚„ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‹ã‚‰å–å¾—
        return self._in_memory_sessions.get(session_id)
    
    async def _generate_initial_clarification_questions(
        self, 
        instruction: Dict[str, str], 
        original_content: str
    ) -> List[str]:
        """æœ€åˆã®æ·±æ˜ã‚Šè³ªå•ã‚’ç”Ÿæˆ"""
        
        if not instruction:
            return ["1on1ã®å†…å®¹ã«ã¤ã„ã¦ã€ã©ã®éƒ¨åˆ†ã‚’æœ€ã‚‚æ”¹å–„ã—ãŸã„ã¨æ„Ÿã˜ã¦ã„ã¾ã™ã‹ï¼Ÿ"]
        
        abstract_concept = instruction.get("abstract_concept", "")
        original_text = instruction.get("original_text", "")
        specific_scope = instruction.get("specific_scope", "")
        excluded_areas = instruction.get("excluded_areas", [])
        key_elements = instruction.get("key_elements", [])
        
        # é™¤å¤–é ˜åŸŸã®æ–‡å­—åˆ—ã‚’æ§‹ç¯‰
        excluded_text = ""
        if excluded_areas:
            excluded_text = f"\nâŒ é™¤å¤–ã™ã¹ãé ˜åŸŸ: {', '.join(excluded_areas)}"
        
        # ä¸»è¦è¦ç´ ã®æ–‡å­—åˆ—ã‚’æ§‹ç¯‰
        key_elements_text = ""
        if key_elements:
            key_elements_text = f"\nğŸ”‘ é‡è¦–ã™ã¹ãè¦ç´ : {', '.join(key_elements)}"
        
        prompt_messages = [
            SystemMessage(content=f"""æ–°äººå–¶æ¥­ãƒãƒ³ãŒä¸Šå¸ã‹ã‚‰ã€Œ{abstract_concept}ã€ã¨ã„ã†æŠ½è±¡çš„ãªæŒ‡ç¤ºã‚’å—ã‘ã¾ã—ãŸã€‚
ã€é‡è¦ãªåˆ¶ç´„ã€‘: è³ªå•ã¯å¿…ãšã€Œ{abstract_concept}ã€ã®æ–‡è„ˆå†…ã§ã®ã¿ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ä¸Šå¸ã®å…·ä½“çš„ãªæŒ‡ç¤ºå†…å®¹: "{original_text}"
å¯¾è±¡ã‚¹ã‚³ãƒ¼ãƒ—: {specific_scope if specific_scope else abstract_concept}{excluded_text}{key_elements_text}

ã€å³å¯†ãªæ–‡è„ˆåˆ¶ç´„ã€‘:
ğŸ¯ è³ªå•ã¯ã€Œ{abstract_concept}ã€ã«ç‰¹åŒ–ã—ãŸå†…å®¹ã®ã¿
âŒ é–¢é€£ã—ãã†ã§ã‚‚ç•°ãªã‚‹é ˜åŸŸã®è³ªå•ã¯çµ¶å¯¾ç¦æ­¢
âœ… ã€Œ{abstract_concept}ã€ã®å…·ä½“çš„ãªå®Ÿè¡Œæ–¹æ³•ãƒ»çµŒé¨“ãƒ»æ„Ÿè¦šã®ã¿ã‚’èã

ã€çµ¶å¯¾ã«é¿ã‘ã‚‹ã¹ãè³ªå•ã€‘:
âŒ ä¸Šå¸ã®æ„å›³æ¨æ¸¬: ã€Œä¸Šå¸ãŒæ±‚ã‚ã‚‹ã€œã¨ã¯ä½•ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿã€
âŒ ä»–äººã®æœŸå¾…: ã€Œã€œã•ã‚“ãŒæœŸå¾…ã—ã¦ã„ã‚‹ã€œã¯ä½•ã§ã™ã‹ï¼Ÿã€  
âŒ æ–‡è„ˆå¤–ã®è³ªå•: ã€Œ{abstract_concept}ã€ä»¥å¤–ã®å–¶æ¥­ã‚¹ã‚­ãƒ«ã«ã¤ã„ã¦

ã€æ–°äººå–¶æ¥­ãƒãƒ³è‡ªèº«ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸè‰¯ã„è³ªå•ï¼ˆã€Œ{abstract_concept}ã€é™å®šï¼‰ã€‘:
âœ… ã€Œ{abstract_concept}ã€ã®å®Ÿä½“é¨“: ã€Œã“ã‚Œã¾ã§ã«{abstract_concept}ã§å›°ã£ãŸçµŒé¨“ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿã€
âœ… ã€Œ{abstract_concept}ã€ã®ç¾åœ¨ã®è¡Œå‹•: ã€Œæ™®æ®µ{abstract_concept}ã‚’ã™ã‚‹æ™‚ã€ã©ã†ã—ã¦ã„ã¾ã™ã‹ï¼Ÿã€
âœ… ã€Œ{abstract_concept}ã€ã®æ„Ÿè¦š: ã€Œ{abstract_concept}ãŒã†ã¾ãã„ã£ãŸæ™‚ã€ã©ã‚“ãªæ„Ÿã˜ã§ã—ãŸã‹ï¼Ÿã€
âœ… ã€Œ{abstract_concept}ã€ã®å®Ÿè¡Œå¯èƒ½ãªè¡Œå‹•: ã€Œæ˜æ—¥ã‹ã‚‰{abstract_concept}ã‚’æ”¹å–„ã™ã‚‹ã¨ã—ãŸã‚‰ï¼Ÿã€

ä¾‹ï¼šã€Œ{abstract_concept}ã€ã«ã¤ã„ã¦
âŒ æ‚ªã„è³ªå•: ã€Œä¸Šå¸ãŒæ±‚ã‚ã‚‹{abstract_concept}ã¨ã¯ä½•ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿã€
âŒ æ–‡è„ˆå¤–ã®è³ªå•: ã€Œã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨èˆ¬ã«ã¤ã„ã¦ã©ã†æ€ã„ã¾ã™ã‹ï¼Ÿã€ï¼ˆ{abstract_concept}ãŒè³‡æ–™ä½œæˆã®å ´åˆï¼‰
âœ… è‰¯ã„è³ªå•: ã€Œã“ã‚Œã¾ã§ã«{abstract_concept}ã§å›°ã£ãŸçµŒé¨“ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿã€

1è¡Œãšã¤ã€ŒQ: ã€ã§å§‹ã¾ã‚‹å½¢å¼ã§ã€å¿…ãšã€Œ{abstract_concept}ã€ã®æ–‡è„ˆå†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""),
            HumanMessage(content=f"ä¸Šå¸ã®æŒ‡ç¤º: \"{original_text}\"\næŠ½è±¡æ¦‚å¿µ: {abstract_concept}\n\nã€Œ{abstract_concept}ã€ã«ç‰¹åŒ–ã—ãŸæ·±æ˜ã‚Šè³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        ]
        
        try:
            response = await self.llm.ainvoke(prompt_messages)
            
            # è³ªå•ã‚’æŠ½å‡º
            questions = []
            for line in response.content.split('\n'):
                line = line.strip()
                if line.startswith('Q:'):
                    questions.append(line[2:].strip())
                elif line.startswith('è³ªå•') and ':' in line:
                    questions.append(line.split(':', 1)[-1].strip())
                elif line and not line.startswith(('1.', '2.', '3.', '4.', '-', 'ãƒ»')):
                    # ç•ªå·ãªã—ã®è³ªå•ã‚‚æ‹¾ã†
                    if 'ï¼Ÿ' in line or '?' in line:
                        questions.append(line)
            
            return questions[:4] if questions else [
                f"ã“ã‚Œã¾ã§ã«{abstract_concept}ã§å›°ã£ãŸçµŒé¨“ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿã©ã‚“ãªå ´é¢ã§ã—ãŸã‹ï¼Ÿ",
                f"æ™®æ®µã€{abstract_concept}ã‚’æ„è­˜ã—ã¦ä½•ã‹ã—ã¦ã„ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                f"{abstract_concept}ãŒã†ã¾ãã„ã£ãŸæ™‚ã¨å›°ã£ãŸæ™‚ã€è‡ªåˆ†ã§ã‚‚é•ã„ã‚’æ„Ÿã˜ã¾ã™ã‹ï¼Ÿ",
                f"æ˜æ—¥ã‹ã‚‰{abstract_concept}ã‚’æ”¹å–„ã™ã‚‹ã¨ã—ãŸã‚‰ã€ä½•ã‹ã‚‰å§‹ã‚ã¦ã¿ãŸã„ã§ã™ã‹ï¼Ÿ"
            ]
            
        except Exception:
            return [
                f"ã“ã‚Œã¾ã§ã«{abstract_concept}ã§å›°ã£ãŸçµŒé¨“ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                f"æ™®æ®µã€{abstract_concept}ã«ã¤ã„ã¦ä½•ã‹æ„è­˜ã—ã¦ã„ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"
            ]
    
    async def _continue_one_on_one_clarification(
        self, 
        session_id: str, 
        user_response: str, 
        session_state: Dict[str, Any],
        db_session: Any
    ) -> Dict[str, Any]:
        """1on1å…·ä½“åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã®ç¶™ç¶šå‡¦ç†ï¼ˆæ•™è‚²çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰"""
        
        current_index = session_state.get("current_instruction_index", 0)
        instructions = session_state.get("abstract_instructions", [])
        conversation_history = session_state.get("conversation_history", [])
        
        if current_index >= len(instructions):
            # å…¨ã¦ã®æŒ‡ç¤ºãŒå‡¦ç†æ¸ˆã¿ â†’ æœ€çµ‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆ
            return await self._generate_final_action_plan_from_session(session_id, session_state, db_session)
        
        current_instruction = instructions[current_index]
        
        # ğŸ¯ ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ãƒã‚§ãƒƒã‚¯: å…·ä½“çš„ãªè¦æ±‚ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        user_request = await self._check_for_specific_user_request(
            user_response, current_instruction
        )
        
        if user_request:
            # å…·ä½“çš„è¦æ±‚ã«å¿œç­”
            return await self._handle_specific_user_request(
                user_request, current_instruction, session_id, db_session
            )
        
        # ğŸ“ æ•™è‚²çš„ãƒã‚§ãƒƒã‚¯: æ–°äººãŒæ¦‚å¿µã‚’ç†è§£ã—ã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
        needs_explanation = await self._check_if_needs_concept_explanation(
            user_response, current_instruction
        )
        
        if needs_explanation:
            # æ¦‚å¿µèª¬æ˜ã‚’æä¾›
            explanation = await self._generate_educational_explanation(
                current_instruction, user_response
            )
            
            return {
                "type": "educational_explanation",
                "explanation": explanation,
                "instruction_being_clarified": current_instruction,
                "stage": "concept_education",
                "stage_description": f"ğŸ“ æ¦‚å¿µèª¬æ˜: ã€Œ{current_instruction.get('abstract_concept', '')}ã€ã«ã¤ã„ã¦",
                "follow_up": "ã“ã®èª¬æ˜ã§ç†è§£ã§ãã¾ã—ãŸã‹ï¼Ÿç†è§£ã§ããŸã‚‰ã€å…·ä½“çš„ãªçµŒé¨“ã‚„è€ƒãˆã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
            }
        
        # ç¾åœ¨ã®å¯¾è©±å±¥æ­´ã«æ–°äººã®å›ç­”ã‚’è¿½åŠ 
        if current_index < len(conversation_history):
            conversation_history[current_index].append({
                "role": "user",
                "content": user_response,
                "timestamp": datetime.utcnow().isoformat()
            })
        else:
            # æ–°ã—ã„æŒ‡ç¤ºã®å¯¾è©±é–‹å§‹
            conversation_history.append([{
                "role": "user", 
                "content": user_response,
                "timestamp": datetime.utcnow().isoformat()
            }])
        
        # å…·ä½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        concreteness_result = await self._check_instruction_concreteness(
            current_instruction, 
            conversation_history[current_index],
            user_response
        )
        
        is_concrete = concreteness_result.get("is_concrete", False)
        practical_readiness = concreteness_result.get("practical_readiness", False)
        concreteness_score = concreteness_result.get("score", 0)
        implementation_gaps = concreteness_result.get("implementation_gaps", [])
        required_clarifications = concreteness_result.get("required_clarifications", [])
        
        # è³ªå•å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        question_count = len([entry for entry in conversation_history[current_index] 
                             if entry.get("role") == "user"])
        
        # æ·±ã„å¯¾è©±ã®ãŸã‚ã®æœ€ä½è³ªå•å›æ•°ï¼ˆå®Ÿç”¨ãƒ¬ãƒ™ãƒ«ï¼‰
        MIN_QUESTIONS = 5
        MAX_QUESTIONS = 7
        
        # è³ªå•å›æ•°ã¨å…·ä½“æ€§ã®ä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯
        enough_questions = question_count >= MIN_QUESTIONS
        max_questions_reached = question_count >= MAX_QUESTIONS
        
        # å®Ÿç”¨ãƒ¬ãƒ™ãƒ«å®Œäº†æ¡ä»¶ï¼š
        # 1. æœ€ä½5å›ã®è³ªå•ã‚’å®Ÿæ–½æ¸ˆã¿
        # 2. 95%ä»¥ä¸Šã®å…·ä½“æ€§ã‚¹ã‚³ã‚¢
        # 3. å®Ÿè·µæº–å‚™å®Œäº†
        # ã¾ãŸã¯æœ€å¤§7å›ã«é”ã—ãŸå ´åˆ
        if (enough_questions and is_concrete and practical_readiness and concreteness_score >= 95) or max_questions_reached:
            # ååˆ†å…·ä½“çš„ â†’ æ¬¡ã®æŒ‡ç¤ºã¸ç§»å‹•
            session_state["clarified_instructions"].append({
                "instruction": current_instruction,
                "conversation": conversation_history[current_index],
                "final_response": user_response,
                "concreteness_score": concreteness_score,
                "clarified_at": datetime.utcnow().isoformat()
            })
            
            session_state["current_instruction_index"] = current_index + 1
            session_state["conversation_history"] = conversation_history
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
            await self._update_one_on_one_session_state(session_id, session_state)
            
            # æ¬¡ã®æŒ‡ç¤ºãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if current_index + 1 < len(instructions):
                next_instruction = instructions[current_index + 1]
                next_questions = await self._generate_initial_clarification_questions(
                    next_instruction, 
                    session_state.get("original_content", "")
                )
                
                return {
                    "type": "one_on_one_clarification",
                    "questions": next_questions,
                    "instruction_being_clarified": next_instruction,
                    "total_instructions": len(instructions),
                    "current_instruction_index": current_index + 1,
                    "stage": "instruction_clarification",
                    "stage_description": f"ğŸ“‹ ä¸Šå¸ã®æŒ‡ç¤ºã®å…·ä½“åŒ– ({current_index + 2}/{len(instructions)})",
                    "previous_instruction_completed": current_instruction.get("abstract_concept", ""),
                    "concreteness_achieved": concreteness_score
                }
            else:
                # å…¨ã¦ã®æŒ‡ç¤ºãŒå…·ä½“åŒ–å®Œäº† â†’ æœ€çµ‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆ
                return await self._generate_final_action_plan_from_session(session_id, session_state, db_session)
        
        else:
            # ã¾ã æŠ½è±¡çš„ â†’ ã‚ˆã‚Šæ·±ã„è³ªå•ã‚’ç”Ÿæˆ
            deeper_questions = await self._generate_deeper_clarification_questions(
                current_instruction,
                conversation_history[current_index],
                implementation_gaps,
                required_clarifications,
                concreteness_score,
                question_count  # è³ªå•å›æ•°ã‚’è¿½åŠ 
            )
            
            # å¯¾è©±å±¥æ­´ã«AIã®è³ªå•ã‚’è¿½åŠ 
            conversation_history[current_index].append({
                "role": "assistant",
                "content": f"æ·±æ˜ã‚Šè³ªå•: {deeper_questions}",
                "timestamp": datetime.utcnow().isoformat()
            })
            
            session_state["conversation_history"] = conversation_history
            await self._update_one_on_one_session_state(session_id, session_state)
            
            # æ®µéšæƒ…å ±ã‚’è¡¨ç¤ºç”¨ã«æº–å‚™
            if question_count <= 2:
                stage_emoji = "ğŸ“‹"
                stage_name = "åŸºæœ¬ç†è§£ç¢ºèª"
            elif question_count <= 4:
                stage_emoji = "ğŸ”"
                stage_name = "å®Ÿä½“é¨“æ·±æ˜ã‚Š"
            elif question_count == 5:
                stage_emoji = "âš™ï¸"
                stage_name = "å®Ÿè¡Œå¯èƒ½æ€§æ¤œè¨¼"
            elif question_count == 6:
                stage_emoji = "ğŸ¤”"
                stage_name = "Whyç†è§£ç¢ºèª"
            else:
                stage_emoji = "âœ…"
                stage_name = "æœ€çµ‚å…·ä½“åŒ–"
            
            return {
                "type": "one_on_one_clarification",
                "questions": deeper_questions,
                "instruction_being_clarified": current_instruction,
                "total_instructions": len(instructions),
                "current_instruction_index": current_index,
                "stage": "instruction_clarification",
                "stage_description": f"{stage_emoji} {stage_name} ({current_index + 1}/{len(instructions)}) - è³ªå• {question_count}/7å›",
                "concreteness_feedback": f"å…·ä½“æ€§: {concreteness_score}% - å®Ÿç”¨ãƒ¬ãƒ™ãƒ«(95%)ã¾ã§æ·±æ˜ã‚Šä¸­",
                "dialogue_progress": f"è³ªå•å›æ•°: {question_count}/7å› | æœ€ä½5å›ã¯å¿…è¦",
                "implementation_gaps": implementation_gaps[:3],  # ä¸è¶³è¦ç´ ã‚’è¡¨ç¤º
                "required_clarifications": required_clarifications[:3]  # å¿…è¦ãªæ˜ç¢ºåŒ–ã‚’è¡¨ç¤º
            }
    
    async def _check_instruction_concreteness(
        self, 
        instruction: Dict[str, str], 
        conversation_history: List[Dict[str, str]],
        latest_response: str
    ) -> Dict[str, Any]:
        """å³æ ¼ãªå¤šæ®µéšå…·ä½“æ€§è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ """
        
        abstract_concept = instruction.get("abstract_concept", "")
        
        # ä¼šè©±å±¥æ­´ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
        conversation_text = "\\n".join([
            f"{entry['role']}: {entry['content']}" for entry in conversation_history
        ])
        
        prompt_messages = [
            SystemMessage(content=f"""å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã®å–¶æ¥­ã‚³ãƒ¼ãƒã¨ã—ã¦ã€æ–°äººå–¶æ¥­ãƒãƒ³ã®å›ç­”ã‚’å³æ ¼ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

è©•ä¾¡å¯¾è±¡ã®æŠ½è±¡çš„æŒ‡ç¤º: "{abstract_concept}"

ã€å³æ ¼ãªå®Ÿç”¨ãƒ¬ãƒ™ãƒ«è©•ä¾¡åŸºæº–ã€‘:

ğŸŸ¢ ãƒ¬ãƒ™ãƒ«5 (95-100%): å®Ÿç”¨å®Œäº†ãƒ¬ãƒ™ãƒ«
- æ˜æ—¥æœ9æ™‚ã‹ã‚‰å®Ÿè¡Œã§ãã‚‹å…·ä½“çš„ãªæ‰‹é †ãŒæ˜è¨˜
- å®Ÿè¡Œé »åº¦ã€æ‰€è¦æ™‚é–“ã€æ¸¬å®šæ–¹æ³•ãŒæ•°å€¤ã§æŒ‡å®š
- å¤±æ•—æ™‚ã®å¯¾å‡¦æ³•ã¾ã§å«ã‚€
- ä»–äººã«ã‚‚æ•™ãˆã‚‰ã‚Œã‚‹ãƒ¬ãƒ™ãƒ«ã®è©³ç´°
ä¾‹: "å•†è«‡é–‹å§‹æ™‚ã«3åˆ†é–“ã€ç›¸æ‰‹ã®æ¥­å‹™çŠ¶æ³ã‚’3ã¤ã®è³ªå•(å£²ä¸Šå‹•å‘/èª²é¡Œ/ç›®æ¨™)ã§èãã€A4ç”¨ç´™ã«ãƒ¡ãƒ¢ã€‚é€±1å›æŒ¯ã‚Šè¿”ã‚Š"

ğŸŸ¡ ãƒ¬ãƒ™ãƒ«4 (80-94%): å®Ÿè¡Œæº–å‚™ãƒ¬ãƒ™ãƒ«  
- å…·ä½“çš„ãªè¡Œå‹•ã¯æ˜ç¢ºã ãŒã€ç´°éƒ¨ã§æ›–æ˜§ã•ãŒæ®‹ã‚‹
- æ¸¬å®šæ–¹æ³•ã¯ç¤ºã•ã‚Œã¦ã„ã‚‹ãŒæ•°å€¤ç›®æ¨™ãŒä¸æ˜ç¢º
- ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚„é »åº¦ãŒã‚„ã‚„æ›–æ˜§
ä¾‹: "å•†è«‡æ™‚ã«ç›¸æ‰‹ã®çŠ¶æ³ã‚’è³ªå•ã—ã¦ãƒ¡ãƒ¢ã‚’å–ã‚‹ã€‚å®šæœŸçš„ã«æŒ¯ã‚Šè¿”ã‚‹"

ğŸŸ  ãƒ¬ãƒ™ãƒ«3 (60-79%): ç†è§£é€²è¡Œãƒ¬ãƒ™ãƒ«
- åŸºæœ¬çš„ãªè¡Œå‹•æ–¹é‡ã¯ç†è§£
- å…·ä½“çš„ãªå®Ÿè¡Œæ–¹æ³•ã«æ›–æ˜§ã•ãŒå¤šã„
- æ¸¬å®šã‚„æŒ¯ã‚Šè¿”ã‚Šæ–¹æ³•ãŒä¸æ˜ç¢º
ä¾‹: "ç›¸æ‰‹ã®çŠ¶æ³ã‚’ã‚ˆãèã„ã¦ç†è§£ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹"

ğŸ”´ ãƒ¬ãƒ™ãƒ«2 (40-59%): æ¦‚å¿µèªè­˜ãƒ¬ãƒ™ãƒ«
- æ¦‚å¿µã¯ç†è§£ã—ã¦ã„ã‚‹ãŒå®Ÿè¡Œæ–¹æ³•ãŒä¸æ˜
- æŠ½è±¡çš„ãªè¡¨ç¾ãŒå¤šã„
ä¾‹: "ã‚‚ã£ã¨ç›¸æ‰‹ã®ã“ã¨ã‚’ç†è§£ã—ãŸã„"

âš« ãƒ¬ãƒ™ãƒ«1 (0-39%): ç†è§£ä¸è¶³ãƒ¬ãƒ™ãƒ«
- æ¦‚å¿µã®ç†è§£ãŒä¸ååˆ†
- å…·ä½“çš„ãªè¡Œå‹•ãŒå…¨ãè¦‹ãˆãªã„
ä¾‹: "é ‘å¼µã‚Šã¾ã™" "æ„è­˜ã—ã¾ã™"

ã€é‡è¦ã€‘: å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã§ã¯95%ä»¥ä¸Šã®ã¿ã‚’ã€Œå®Œäº†ã€ã¨åˆ¤å®šã—ã¦ãã ã•ã„ã€‚
90%ä»¥ä¸‹ã¯å¿…ãšè¿½åŠ ã®æ·±æ˜ã‚ŠãŒå¿…è¦ã§ã™ã€‚

ã€å®Ÿè¡Œå¯èƒ½æ€§ã®å³å¯†ãƒã‚§ãƒƒã‚¯é …ç›®ã€‘:
âœ… æ™‚é–“è¨­å®š: ã€Œæ˜æ—¥æœ9æ™‚ã‹ã‚‰ã€ã€Œæ¯å›3åˆ†é–“ã€ç­‰ã®å…·ä½“çš„æ™‚é–“
âœ… å ´æ‰€ãƒ»ç’°å¢ƒ: ã€Œå•†è«‡é–‹å§‹æ™‚ã«ã€ã€ŒA4ç”¨ç´™ã«ã€ç­‰ã®å…·ä½“çš„å ´æ‰€ãƒ»é“å…·
âœ… æ‰‹é †è©³ç´°: ã€Œ3ã¤ã®è³ªå•(å£²ä¸Šãƒ»èª²é¡Œãƒ»ç›®æ¨™)ã§èãã€ç­‰ã®ã‚¹ãƒ†ãƒƒãƒ—
âœ… æ¸¬å®šæ–¹æ³•: ã€Œé€±1å›æŒ¯ã‚Šè¿”ã‚‹ã€ã€Œãƒ¡ãƒ¢ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã€ç­‰ã®ç¢ºèªæ–¹æ³•
âœ… å¤±æ•—å¯¾å‡¦: ã€Œã†ã¾ãã„ã‹ãªã„æ™‚ã¯XXã™ã‚‹ã€ç­‰ã®ä»£æ›¿æ¡ˆ
âœ… ãƒªã‚½ãƒ¼ã‚¹: å¿…è¦ãªé“å…·ãƒ»æ¨©é™ãƒ»æ™‚é–“ãŒæ˜ç¢ºã§å®Ÿç¾å¯èƒ½

ä»¥ä¸‹ã®JSONå½¢å¼ã§å³æ ¼ã«è©•ä¾¡ã—ã¦ãã ã•ã„ï¼š
```json
{{
  "level": 1-5,
  "score": 0-100,
  "is_concrete": true/false,
  "practical_readiness": true/false,
  "executable_tomorrow": true/false,
  "time_specification": true/false,
  "resource_clarity": true/false,
  "measurement_method": true/false,
  "failure_handling": true/false,
  "implementation_gaps": ["ä¸è¶³è¦ç´ 1", "ä¸è¶³è¦ç´ 2"],
  "strong_points": ["å…·ä½“çš„ãªè¦ç´ 1", "å…·ä½“çš„ãªè¦ç´ 2"], 
  "required_clarifications": ["å¿…è¦ãªæ˜ç¢ºåŒ–1", "å¿…è¦ãªæ˜ç¢ºåŒ–2"],
  "next_focus": "æ¬¡ã«é‡ç‚¹çš„ã«ç¢ºèªã™ã¹ãç‚¹",
  "why_understanding": true/false,
  "practical_barriers": ["å®Ÿè¡Œä¸Šã®éšœå®³1", "éšœå®³2"]
}}
```"""),
            HumanMessage(content=f"ä¼šè©±å±¥æ­´ï¼š\\n{conversation_text}\\n\\næœ€æ–°ã®å›ç­”: {latest_response}\\n\\nå³æ ¼ãªå®Ÿç”¨ãƒ¬ãƒ™ãƒ«åŸºæº–ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚")
        ]
        
        try:
            response = await self.llm.ainvoke(prompt_messages)
            response_text = response.content.strip()
            
            # JSONã‚’æŠ½å‡º
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                if json_end != -1:
                    response_text = response_text[json_start:json_end].strip()
            
            result = json.loads(response_text)
            
            # å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã§ã¯95%ä»¥ä¸Šã‹ã¤å®Ÿè¡Œå¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯é …ç›®ã‚’ã‚¯ãƒªã‚¢ãŒå¿…è¦
            score = result.get("score", 0)
            executable_tomorrow = result.get("executable_tomorrow", False)
            time_specification = result.get("time_specification", False) 
            resource_clarity = result.get("resource_clarity", False)
            measurement_method = result.get("measurement_method", False)
            
            # å³æ ¼ãªå®Ÿè¡Œå¯èƒ½æ€§åˆ¤å®š
            practical_requirements_met = all([
                executable_tomorrow,
                time_specification,
                resource_clarity,
                measurement_method
            ])
            
            if score < 95 or not practical_requirements_met:
                result["is_concrete"] = False
                result["practical_readiness"] = False
            
            return result
            
        except Exception:
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å³æ ¼ã«ä½è©•ä¾¡
            return {
                "level": 2,
                "score": 30,
                "is_concrete": False,
                "practical_readiness": False,
                "implementation_gaps": ["å…·ä½“çš„ãªæ‰‹é †", "å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°", "æ¸¬å®šæ–¹æ³•", "æ•°å€¤ç›®æ¨™"],
                "strong_points": [],
                "required_clarifications": ["å®Ÿè¡Œæ‰‹é †ã®è©³ç´°åŒ–", "æ¸¬å®šå¯èƒ½ãªç›®æ¨™è¨­å®š"],
                "next_focus": "å…·ä½“çš„ãªå®Ÿè¡Œæ–¹æ³•ã®æ˜ç¢ºåŒ–",
                "why_understanding": False,
                "measurability": False
            }
    
    async def _update_one_on_one_session_state(self, session_id: str, state_data: Dict[str, Any]) -> None:
        """1on1ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°"""
        # Redisã«ä¿å­˜ã‚’è©¦è¡Œã€å¤±æ•—ã—ãŸã‚‰ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã«ä¿å­˜
        if self.memory_service.redis_client:
            try:
                session_key = f"one_on_one_session:{session_id}"
                await self.memory_service.redis_client.setex(
                    session_key,
                    86400,  # 24æ™‚é–“
                    json.dumps(state_data, ensure_ascii=False)
                )
            except Exception:
                # Redisã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                self._in_memory_sessions[session_id] = state_data
        else:
            # RedisãŒãªã„å ´åˆã¯ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã«ä¿å­˜
            self._in_memory_sessions[session_id] = state_data
    
    async def _generate_deeper_clarification_questions(
        self, 
        instruction: Dict[str, str], 
        conversation_history: List[Dict[str, str]],
        implementation_gaps: List[str],
        required_clarifications: List[str],
        concreteness_score: int,
        question_count: int
    ) -> List[str]:
        """ã‚ˆã‚Šæ·±ã„å…·ä½“åŒ–è³ªå•ã‚’ç”Ÿæˆ"""
        
        abstract_concept = instruction.get("abstract_concept", "")
        specific_scope = instruction.get("specific_scope", "")
        excluded_areas = instruction.get("excluded_areas", [])
        key_elements = instruction.get("key_elements", [])
        original_text = instruction.get("original_text", "")
        
        # é™¤å¤–é ˜åŸŸã®æ–‡å­—åˆ—ã‚’æ§‹ç¯‰
        excluded_text = ""
        if excluded_areas:
            excluded_text = f"\nâŒ é™¤å¤–ã™ã¹ãé ˜åŸŸ: {', '.join(excluded_areas)}"
        
        # ä¸»è¦è¦ç´ ã®æ–‡å­—åˆ—ã‚’æ§‹ç¯‰
        key_elements_text = ""
        if key_elements:
            key_elements_text = f"\nğŸ”‘ é‡è¦–ã™ã¹ãè¦ç´ : {', '.join(key_elements)}"
        
        # è³ªå•æ®µéšã®æ±ºå®š
        if question_count <= 2:
            question_stage = "åŸºæœ¬ç†è§£ç¢ºèª"
            stage_focus = "æ¦‚å¿µã®åŸºæœ¬çš„ç†è§£ã¨çµŒé¨“ã®ç¢ºèª"
        elif question_count <= 4:
            question_stage = "å®Ÿä½“é¨“æ·±æ˜ã‚Š"
            stage_focus = "å…·ä½“çš„ãªçµŒé¨“ã‚„çŠ¶æ³ã®è©³ç´°åŒ–"
        elif question_count == 5:
            question_stage = "å®Ÿè¡Œå¯èƒ½æ€§æ¤œè¨¼"
            stage_focus = "æ˜æ—¥ã‹ã‚‰å®Ÿè¡Œã§ãã‚‹å…·ä½“çš„ãªæ‰‹é †ã®ç¢ºèª"
        elif question_count == 6:
            question_stage = "Whyç†è§£ç¢ºèª"
            stage_focus = "ãªãœãã®è¡Œå‹•ãŒé‡è¦ã‹ã®ç†è§£ç¢ºèª"
        else:
            question_stage = "æœ€çµ‚å…·ä½“åŒ–"
            stage_focus = "æ¸¬å®šå¯èƒ½ã§ä»–äººã«ã‚‚èª¬æ˜ã§ãã‚‹ãƒ¬ãƒ™ãƒ«ã®è©³ç´°åŒ–"
        
        # ä¼šè©±å±¥æ­´ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
        conversation_text = "\\n".join([
            f"{entry['role']}: {entry['content']}" for entry in conversation_history
        ])
        
        prompt_messages = [
            SystemMessage(content=f"""å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã®å–¶æ¥­ã‚³ãƒ¼ãƒã¨ã—ã¦ã€æ®µéšçš„ãªæ·±æ˜ã‚Šè³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€å¯¾è©±ã®ç¾çŠ¶ã€‘:
- è³ªå•å›æ•°: {question_count}/7å›
- ç¾åœ¨ã®æ®µéš: {question_stage}
- ã“ã®æ®µéšã®ç„¦ç‚¹: {stage_focus}
- å…·ä½“æ€§ã‚¹ã‚³ã‚¢: {concreteness_score}%

å¯¾è±¡ã®æŠ½è±¡çš„æŒ‡ç¤º: "{abstract_concept}"
ä¸Šå¸ã®å…·ä½“çš„ãªæŒ‡ç¤ºå†…å®¹: "{original_text}"
å¯¾è±¡ã‚¹ã‚³ãƒ¼ãƒ—: {specific_scope if specific_scope else abstract_concept}{excluded_text}{key_elements_text}
å®Ÿè£…ä¸Šã®ä¸è¶³è¦ç´ : {implementation_gaps}
å¿…è¦ãªæ˜ç¢ºåŒ–äº‹é …: {required_clarifications}

ã€æ®µéšåˆ¥è³ªå•æˆ¦ç•¥ã€‘:
ğŸ“‹ åŸºæœ¬ç†è§£ç¢ºèª (1-2å›ç›®): æ¦‚å¿µç†è§£ã¨åŸºæœ¬çš„ãªçµŒé¨“
ğŸ” å®Ÿä½“é¨“æ·±æ˜ã‚Š (3-4å›ç›®): å…·ä½“çš„ãªçŠ¶æ³ã¨è©³ç´°ãªçµŒé¨“
âš™ï¸ å®Ÿè¡Œå¯èƒ½æ€§æ¤œè¨¼ (5å›ç›®): å®Ÿéš›ã®æ‰‹é †ã¨æ¸¬å®šæ–¹æ³•
ğŸ¤” Whyç†è§£ç¢ºèª (6å›ç›®): ãªãœãã®è¡Œå‹•ãŒé‡è¦ã‹ã®ç†è§£
âœ… æœ€çµ‚å…·ä½“åŒ– (7å›ç›®): ä»–äººã«èª¬æ˜ã§ãã‚‹ãƒ¬ãƒ™ãƒ«ã®å®Œå…¨ãªè©³ç´°

ã€Whyç†è§£ç¢ºèªã®é‡è¦æ€§ã€‘:
æ–°äººãŒã€Œãªãœãã®è¡Œå‹•ãŒé‡è¦ãªã®ã‹ã€ã‚’ç†è§£ã—ã¦ã„ã‚‹ã“ã¨ã§ï¼š
- ç¶™ç¶šçš„ãªå®Ÿè¡ŒãŒå¯èƒ½ã«ãªã‚‹
- çŠ¶æ³ã«å¿œã˜ãŸå¿œç”¨ãŒã§ãã‚‹  
- ä»–ã®ãƒ¡ãƒ³ãƒãƒ¼ã«ã‚‚èª¬æ˜ã§ãã‚‹
- ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ãŒç¶­æŒã•ã‚Œã‚‹

ã€å³å¯†ãªæ–‡è„ˆåˆ¶ç´„ã€‘:
ğŸ¯ æ·±æ˜ã‚Šè³ªå•ã¯ã€Œ{abstract_concept}ã€ã«ç‰¹åŒ–ã—ãŸå†…å®¹ã®ã¿
âŒ é–¢é€£ã—ãã†ã§ã‚‚ç•°ãªã‚‹é ˜åŸŸã®è³ªå•ã¯çµ¶å¯¾ç¦æ­¢
âœ… ã€Œ{abstract_concept}ã€ã®å…·ä½“çš„ãªå®Ÿè¡Œæ–¹æ³•ãƒ»çµŒé¨“ãƒ»æ‰‹é †ã®ã¿ã‚’æ·±æ˜ã‚Š

ã€çµ¶å¯¾ã«é¿ã‘ã‚‹ã¹ãæ·±æ˜ã‚Šè³ªå•ã€‘:
âŒ ä¸Šå¸ã®æ„å›³æ¨æ¸¬: ã€Œä¸Šå¸ãŒè¨€ã„ãŸã‹ã£ãŸã“ã¨ã¯ä½•ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿã€
âŒ ä»–äººã®æœŸå¾…: ã€ŒãŠå®¢æ§˜ãŒæœŸå¾…ã—ã¦ã„ã‚‹ã€œã¯ä½•ã§ã™ã‹ï¼Ÿã€
âŒ ä¼šç¤¾ã®æ–¹é‡: ã€Œä¼šç¤¾ã¨ã—ã¦æ±‚ã‚ã‚‰ã‚Œã‚‹ã€œã¯ï¼Ÿã€
âŒ æ–‡è„ˆå¤–ã®è³ªå•: ã€Œ{abstract_concept}ã€ä»¥å¤–ã®é ˜åŸŸã«ã¤ã„ã¦

ã€æ–°äººå–¶æ¥­ãƒãƒ³è‡ªèº«ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸæ·±æ˜ã‚Šè³ªå•ï¼ˆã€Œ{abstract_concept}ã€é™å®šï¼‰ã€‘:
âœ… ã€Œ{abstract_concept}ã€ã®å…·ä½“çš„ä½“é¨“: ã€Œã“ã‚Œã¾ã§ã«{abstract_concept}ã‚’ã—ãŸçµŒé¨“ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿã€
âœ… ã€Œ{abstract_concept}ã€ã®ç¾åœ¨ã®æ„Ÿè¦š: ã€Œ{abstract_concept}ã‚’ã™ã‚‹æ™‚ã€ã©ã‚“ãªé¢¨ã«æ„Ÿã˜ã¾ã™ã‹ï¼Ÿã€
âœ… ã€Œ{abstract_concept}ã€ã®å®Ÿè¡Œå¯èƒ½ãªè¡Œå‹•: ã€Œæ˜æ—¥ã‹ã‚‰{abstract_concept}ã‚’æ”¹å–„ã™ã‚‹ã¨ã—ãŸã‚‰ã€ä½•åˆ†ãã‚‰ã„ï¼Ÿã€
âœ… ã€Œ{abstract_concept}ã€ã§ã®è‡ªåˆ†ã®åˆ¤æ–­: ã€Œ{abstract_concept}ã§Aã¨Bã€ã©ã¡ã‚‰ã‚’é¸ã³ã¾ã™ã‹ï¼Ÿã€

ã€ã€Œ{abstract_concept}ã€ã«ç‰¹åŒ–ã—ãŸæ·±æ˜ã‚Šè³ªå•ä¾‹ã€‘:
- ã€Œã“ã‚Œã¾ã§ã«{abstract_concept}ãŒã†ã¾ãã„ã£ãŸçµŒé¨“ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿãã®æ™‚ä½•ã‚’ã—ã¦ã„ã¾ã—ãŸã‹ï¼Ÿã€
- ã€Œæ™®æ®µ{abstract_concept}ã‚’ã™ã‚‹æ™‚ã€ä¸€ç•ªå›°ã‚‹ã®ã¯ã©ã‚“ãªå ´é¢ã§ã™ã‹ï¼Ÿã€
- ã€Œæ˜æ—¥{abstract_concept}ã‚’æ”¹å–„ã™ã‚‹ã¨ã—ãŸã‚‰ã€ä½•ã‹ã‚‰å§‹ã‚ã¾ã™ã‹ï¼Ÿã€

æ³¨æ„: è³ªå•ã¯å¿…ãšã€Œ{abstract_concept}ã€ã®ç¯„å›²å†…ã§ç”Ÿæˆã—ã€ä»–ã®å–¶æ¥­ã‚¹ã‚­ãƒ«ã‚„ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨èˆ¬ã«é€¸è„±ã—ãªã„ã“ã¨ã€‚

1è¡Œãšã¤ã€ŒQ: ã€ã§å§‹ã¾ã‚‹å½¢å¼ã§2-3å€‹ã®è³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"""),
            HumanMessage(content=f"ã“ã‚Œã¾ã§ã®ä¼šè©±ï¼š\\n{conversation_text}\\n\\nã€Œ{abstract_concept}ã€ã«ç‰¹åŒ–ã—ãŸã‚ˆã‚Šå…·ä½“çš„ãªæ·±æ˜ã‚Šè³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        ]
        
        try:
            response = await self.llm.ainvoke(prompt_messages)
            
            # è³ªå•ã‚’æŠ½å‡º
            questions = []
            for line in response.content.split('\\n'):
                line = line.strip()
                if line.startswith('Q:'):
                    questions.append(line[2:].strip())
                elif 'ï¼Ÿ' in line or '?' in line:
                    if not line.startswith(('ä¾‹ï¼š', 'â€»', 'æ³¨ï¼š')):
                        questions.append(line)
            
            return questions[:3] if questions else [
                f"ã“ã‚Œã¾ã§ã«{abstract_concept}ãŒã†ã¾ãã„ã£ãŸçµŒé¨“ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿãã®æ™‚ä½•ã‚’ã—ã¦ã„ã¾ã—ãŸã‹ï¼Ÿ",
                f"æ™®æ®µ{abstract_concept}ã§ä¸€ç•ªå›°ã‚‹ã®ã¯ã©ã‚“ãªå ´é¢ã§ã™ã‹ï¼Ÿ",
                f"æ˜æ—¥ã‹ã‚‰{abstract_concept}ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€ä½•åˆ†ãã‚‰ã„æ™‚é–“ã‚’ã‹ã‘ã¦ã¿ã¾ã™ã‹ï¼Ÿ"
            ]
            
        except Exception:
            return [
                f"ã“ã‚Œã¾ã§ã«{abstract_concept}ã§å›°ã£ãŸçµŒé¨“ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                f"æ™®æ®µ{abstract_concept}ã«ã¤ã„ã¦ä½•ã‹æ°—ã‚’ã¤ã‘ã¦ã„ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                f"æ˜æ—¥ã‹ã‚‰ä½•ã‹æ–°ã—ã„ã“ã¨ã‚’è©¦ã—ã¦ã¿ã‚‹ã¨ã—ãŸã‚‰ã€ä½•ã‚’ã—ã¾ã™ã‹ï¼Ÿ"
            ]
    
    async def _generate_final_action_plan_from_session(
        self, 
        session_id: str, 
        session_state: Dict[str, Any], 
        db_session: Any
    ) -> Dict[str, Any]:
        """å¯¾è©±å‹å…·ä½“åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰æœ€çµ‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ"""
        
        clarified_instructions = session_state.get("clarified_instructions", [])
        original_content = session_state.get("original_content", "")
        
        if not clarified_instructions:
            return {
                "type": "error",
                "message": "å…·ä½“åŒ–ã•ã‚ŒãŸæŒ‡ç¤ºãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚‚ã†ä¸€åº¦1on1ã®å†…å®¹ã‹ã‚‰å§‹ã‚ã¦ãã ã•ã„ã€‚"
            }
        
        # å…·ä½“åŒ–ã•ã‚ŒãŸå…¨ã¦ã®æŒ‡ç¤ºã‚’ã¾ã¨ã‚ã‚‹
        all_clarifications = []
        for clarified in clarified_instructions:
            instruction = clarified["instruction"]
            conversation = clarified["conversation"]
            final_response = clarified["final_response"]
            
            all_clarifications.append({
                "original_abstract": instruction.get("abstract_concept", ""),
                "clarification_conversation": conversation,
                "concrete_outcome": final_response,
                "concreteness_score": clarified.get("concreteness_score", 0)
            })
        
        # LLMã«æœ€çµ‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆã‚’ä¾é ¼
        clarifications_text = "\\n\\n".join([
            f"æŒ‡ç¤º: {c['original_abstract']}\\nå…·ä½“åŒ–çµæœ: {c['concrete_outcome']}"
            for c in all_clarifications
        ])
        
        prompt_messages = [
            SystemMessage(content=f"""æ–°äººå–¶æ¥­ãƒãƒ³ã¨ã®å¯¾è©±ã‚’é€šã˜ã¦ã€ä¸Šå¸ã®æŠ½è±¡çš„ãªæŒ‡ç¤ºãŒå…·ä½“åŒ–ã•ã‚Œã¾ã—ãŸã€‚
ã“ã‚Œã‚‰ã®å…·ä½“åŒ–ã•ã‚ŒãŸå†…å®¹ã‚’çµ±åˆã—ã¦ã€å®Ÿè·µçš„ãªæœ€çµ‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
```json
{{
  "final_summary": {{
    "title": "1on1ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ æœ€çµ‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³",
    "priority_actions": [
      {{
        "action": "å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³",
        "specific_steps": ["ã‚¹ãƒ†ãƒƒãƒ—1", "ã‚¹ãƒ†ãƒƒãƒ—2", "ã‚¹ãƒ†ãƒƒãƒ—3"],
        "frequency": "å®Ÿè¡Œé »åº¦",
        "measurement": "æˆæœæ¸¬å®šæ–¹æ³•"
      }}
    ],
    "implementation_timeline": {{
      "immediately": "ä»Šã™ãå®Ÿè¡Œã™ã‚‹ã“ã¨",
      "this_week": "ä»Šé€±ä¸­ã«å®Ÿè¡Œã™ã‚‹ã“ã¨", 
      "this_month": "ä»Šæœˆä¸­ã«å®Ÿè¡Œã™ã‚‹ã“ã¨"
    }},
    "success_metrics": [
      {{
        "metric": "æ¸¬å®šæŒ‡æ¨™",
        "target": "ç›®æ¨™å€¤",
        "how_to_measure": "æ¸¬å®šæ–¹æ³•"
      }}
    ],
    "next_steps": ["æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—1", "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—2"]
  }},
  "dialogue_summary": {{
    "instructions_clarified": {len(clarified_instructions)},
    "total_interactions": "å¯¾è©±ã®ç·æ•°",
    "key_insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2"],
    "concreteness_improvement": "å…·ä½“æ€§ã®å‘ä¸Šåº¦"
  }}
}}
```

é‡è¦: å…¨ã¦æ–°äººå–¶æ¥­ãƒãƒ³ãŒæ˜æ—¥ã‹ã‚‰å®Ÿè¡Œã§ãã‚‹å…·ä½“çš„ãªå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚"""),
            HumanMessage(content=f"å…ƒã®1on1å†…å®¹ï¼š\\n{original_content}\\n\\nå…·ä½“åŒ–ã•ã‚ŒãŸæŒ‡ç¤ºï¼š\\n{clarifications_text}\\n\\næœ€çµ‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        ]
        
        try:
            response = await self.llm.ainvoke(prompt_messages)
            response_text = response.content.strip()
            
            # JSONã‚’æŠ½å‡º
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                if json_end != -1:
                    response_text = response_text[json_start:json_end].strip()
            
            action_plan_data = json.loads(response_text)
            
            # 1on1ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å®Œäº†ã¨ã—ã¦ãƒãƒ¼ã‚¯ï¼ˆå‰Šé™¤ï¼‰
            if self.memory_service.redis_client:
                try:
                    session_key = f"one_on_one_session:{session_id}"
                    await self.memory_service.redis_client.delete(session_key)
                except Exception:
                    pass  # Redisã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
            
            # ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‹ã‚‰ã‚‚å‰Šé™¤
            if session_id in self._in_memory_sessions:
                del self._in_memory_sessions[session_id]
            
            return {
                "type": "one_on_one_final_plan",
                "data": action_plan_data,
                "clarification_history": all_clarifications,
                "analysis_method": "dialogue_based_concretization"
            }
            
        except Exception as e:
            return {
                "type": "error",
                "message": f"æœ€çµ‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            }
    
    # === æ•™è‚²çš„èª¬æ˜æ©Ÿèƒ½ ===
    
    async def _check_if_needs_concept_explanation(
        self,
        user_response: str,
        instruction: Dict[str, Any]
    ) -> bool:
        """æ–°äººãŒæ¦‚å¿µèª¬æ˜ã‚’å¿…è¦ã¨ã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        
        abstract_concept = instruction.get("abstract_concept", "")
        
        # çµŒé¨“ãŒãªã„ã“ã¨ã‚’ç¤ºã™æœ‰åŠ¹ãªå›ç­”
        no_experience_indicators = [
            "ã‚ã‚Šã¾ã›ã‚“", "ãªã„ã§ã™", "çµŒé¨“ãŒãªã„", "çµŒé¨“ã‚ã‚Šã¾ã›ã‚“",
            "ã—ãŸã“ã¨ãŒãªã„", "ãªã„", "ç‰¹ã«ãªã„", "ç‰¹ã«ã‚ã‚Šã¾ã›ã‚“"
        ]
        
        # æœ‰åŠ¹ãªå¦å®šå›ç­”ã‹ãƒã‚§ãƒƒã‚¯
        normalized_response = user_response.strip()
        for indicator in no_experience_indicators:
            if indicator in normalized_response:
                return False  # çµŒé¨“ãŒãªã„ã¨ã„ã†æœ‰åŠ¹ãªå›ç­”ãªã®ã§èª¬æ˜ã¯ä¸è¦
        
        # æ˜ç¢ºãªç†è§£ä¸è¶³ã®ã‚µã‚¤ãƒ³
        confusion_indicators = [
            "ã£ã¦ä½•ï¼Ÿ", "ã¨ã¯ï¼Ÿ", "åˆ†ã‹ã‚‰ãªã„", "ã‚ã‹ã‚‰ãªã„",
            "çŸ¥ã‚‰ãªã„", "åˆã‚ã¦èã", "æ„å‘³ãŒ", "ã©ã†ã„ã†",
            "ã‚ˆãã‚ã‹ã‚‰ãªã„", "ç†è§£ã§ããªã„", "ï¼Ÿï¼Ÿï¼Ÿ",
            "ä½•ã®ã“ã¨", "å…·ä½“çš„ã«ä½•", "ã©ã†é•ã†"
        ]
        
        # åŸºæœ¬çš„ãªãƒã‚§ãƒƒã‚¯
        for indicator in confusion_indicators:
            if indicator in user_response:
                return True
        
        # LLMã«ã‚ˆã‚‹è©³ç´°ãƒã‚§ãƒƒã‚¯
        prompt_messages = [
            SystemMessage(content=f"""ã‚ãªãŸã¯æ•™è‚²å¿ƒç†å­¦ã®å°‚é–€å®¶ã§ã™ã€‚

æ–‡è„ˆï¼š
- ä¸Šå¸ãŒæ–°äººã«ã€Œ{abstract_concept}ã€ã«ã¤ã„ã¦è³ªå•ã—ã¦ã„ã¾ã™
- æ–°äººãŒå›ç­”ã—ã¾ã—ãŸ

æ–°äººã®å›ç­”ã‚’åˆ†æã—ã€ä»¥ä¸‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ï¼š
1. æ–°äººã¯ã“ã®æ¦‚å¿µã‚’ç†è§£ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ
2. æ¦‚å¿µã®èª¬æ˜ãŒå¿…è¦ã§ã™ã‹ï¼Ÿ

åˆ¤å®šã®éš›ã¯ã€å›ç­”ã®å†…å®¹ã¨æ–‡è„ˆã‹ã‚‰æ–°äººã®ç†è§£åº¦ã‚’ç·åˆçš„ã«åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
çŸ­ã„å›ç­”ã§ã‚‚ã€æ–‡è„ˆã«é©ã—ãŸå†…å®¹ã§ã‚ã‚Œã°ç†è§£ã—ã¦ã„ã‚‹ã¨åˆ¤æ–­ã§ãã¾ã™ã€‚

å›ç­”ï¼štrueï¼ˆèª¬æ˜ãŒå¿…è¦ï¼‰ã¾ãŸã¯falseï¼ˆç†è§£ã—ã¦ã„ã‚‹ï¼‰"""),
            HumanMessage(content=f"æ–°äººã®å›ç­”: {user_response}")
        ]
        
        try:
            response = await self.llm.ainvoke(prompt_messages)
            return "true" in response.content.lower()
        except Exception:
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯æ··ä¹±ã®æŒ‡æ¨™ãŒã‚ã‚‹å ´åˆã®ã¿èª¬æ˜ãŒå¿…è¦ã¨åˆ¤å®š
            return any(indicator in user_response for indicator in confusion_indicators)
    
    async def _generate_educational_explanation(
        self,
        instruction: Dict[str, Any],
        user_response: str
    ) -> str:
        """æ•™è‚²çš„ãªæ¦‚å¿µèª¬æ˜ã‚’ç”Ÿæˆ"""
        
        abstract_concept = instruction.get("abstract_concept", "")
        original_text = instruction.get("original_text", "")
        
        prompt_messages = [
            SystemMessage(content=f"""æ–°äººå–¶æ¥­ãƒãƒ³ãŒã€Œ{abstract_concept}ã€ã«ã¤ã„ã¦ç†è§£ã§ããšã«ã„ã¾ã™ã€‚

æ–°äººã«ã¨ã£ã¦åˆ†ã‹ã‚Šã‚„ã™ã„èª¬æ˜ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

èª¬æ˜ã«å«ã‚ã‚‹è¦ç´ ï¼š
1. æ¦‚å¿µã®åŸºæœ¬çš„ãªå®šç¾©ï¼ˆå°‚é–€ç”¨èªã‚’é¿ã‘ã¦ï¼‰
2. å–¶æ¥­æ´»å‹•ã§ã®å…·ä½“ä¾‹ï¼ˆ3ã¤ç¨‹åº¦ï¼‰
3. ãªãœé‡è¦ãªã®ã‹ï¼ˆå…·ä½“çš„ãªãƒ¡ãƒªãƒƒãƒˆï¼‰
4. ã‚ˆãã‚ã‚‹èª¤è§£ã®è¨‚æ­£
5. æ–°äººã§ã‚‚ä»Šæ—¥ã‹ã‚‰æ„è­˜ã§ãã‚‹ãƒã‚¤ãƒ³ãƒˆ

è¦ªã—ã¿ã‚„ã™ãã€åˆ†ã‹ã‚Šã‚„ã™ã„èª¬æ˜ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
ä¸Šå¸ã®ç™ºè¨€: "{original_text}"
æ–°äººã®å›°æƒ‘: "{user_response}" """),
            HumanMessage(content=f"ã€Œ{abstract_concept}ã€ã«ã¤ã„ã¦ã€æ–°äººå–¶æ¥­ãƒãƒ³ã«åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚")
        ]
        
        try:
            response = await self.llm.ainvoke(prompt_messages)
            return response.content.strip()
        except Exception:
            return f"""ã€Œ{abstract_concept}ã€ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã­ã€‚

ã“ã‚Œã¯å–¶æ¥­æ´»å‹•ã«ãŠã„ã¦é‡è¦ãªè¦ç´ ã®ä¸€ã¤ã§ã™ã€‚å…·ä½“çš„ã«ã¯ã€ãŠå®¢æ§˜ã¨ã®ã‚„ã‚Šå–ã‚Šã‚„ææ¡ˆæ´»å‹•ã§æ„è­˜ã™ã¹ããƒã‚¤ãƒ³ãƒˆã‚’æŒ‡ã—ã¦ã„ã¾ã™ã€‚

ã¾ãšã¯ã€Œ{abstract_concept}ã€ãŒã©ã†ã„ã†ã‚‚ã®ã‹ã€ä¸€ç·’ã«å…·ä½“çš„ã«è€ƒãˆã¦ã„ãã¾ã—ã‚‡ã†ã€‚"""
    
    # === ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚èªè­˜ãƒ»å¿œç­”æ©Ÿèƒ½ ===
    
    async def _check_for_specific_user_request(
        self,
        user_response: str,
        instruction: Dict[str, Any]
    ) -> Optional[Dict[str, str]]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…·ä½“çš„ãªè¦æ±‚ã‚’ãƒã‚§ãƒƒã‚¯"""
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªåˆ†ã®çµŒé¨“ã‚„äº‹ä¾‹ã‚’å…±æœ‰ã—ã¦ã„ã‚‹ã‹ã‚’ãƒã‚§ãƒƒã‚¯
        experience_indicators = [
            "ä¾‹ãˆã°ã€", "å…·ä½“çš„ã«ã¯ã€", "å®Ÿéš›ã«", "ã“ã‚Œã¾ã§ã«", "éå»ã«", 
            "ã¾ã—ãŸ", "ã§ã—ãŸ", "ã—ã¦ã„ãŸ", "ä½œæˆã—ã¾ã—ãŸ", "ã—ã¾ã—ãŸ",
            "æ§‹æˆã—", "ç”¨ã„ã¦", "å®ˆã£ãŸ", "åŠ¹æœçš„ã§ã—ãŸ", "ã“ã¨ã§",
            "ç‚¹ã‚‚", "é †ã«", "é¿ã‘", "æ•´ç†ã—ãŸ"
        ]
        
        # çµŒé¨“å…±æœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¤‡æ•°å«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯è¦æ±‚ã§ã¯ãªã„
        matching_patterns = sum(1 for pattern in experience_indicators if pattern in user_response)
        if matching_patterns >= 2:  # è¤‡æ•°ã®çµŒé¨“æŒ‡æ¨™ãŒã‚ã‚Œã°çµŒé¨“å…±æœ‰ã¨åˆ¤å®š
            return None
        
        # æ˜ç¢ºãªè¦æ±‚ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ (ã‚ˆã‚Šå³å¯†ã«)
        request_patterns = {
            "example_request": ["ä¾‹ã‚’æ•™ãˆã¦", "ä¾‹ã‚’è¦‹ã›ã¦", "å…·ä½“ä¾‹ã‚’ãã ã•ã„", "ã‚µãƒ³ãƒ—ãƒ«ã‚’ãã ã•ã„", "å®Ÿä¾‹ãŒæ¬²ã—ã„"],
            "template_request": ["ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’", "ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’", "ã²ãªå½¢ã‚’", "æ§˜å¼ã‚’"],
            "reference_request": ["å‚è€ƒè³‡æ–™ã‚’", "ãŠæ‰‹æœ¬ã‚’", "è¦‹æœ¬ã‚’", "è‰¯ã„ä¾‹ã‚’æ•™ãˆã¦"],
            "knowledge_request": ["ãƒŠãƒ¬ãƒƒã‚¸ã‚’", "è³‡æ–™ã‚’ãã ã•ã„", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’", "å…ˆè¼©ã®ä¾‹ã‚’", "ç¤¾å†…ã®ä¾‹ã‚’"]
        }
        
        # ã‚ˆã‚Šå³å¯†ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        for request_type, patterns in request_patterns.items():
            if any(pattern in user_response for pattern in patterns):
                return {
                    "type": request_type,
                    "original_request": user_response,
                    "abstract_concept": instruction.get("abstract_concept", "")
                }
        
        # LLMã«ã‚ˆã‚‹è©³ç´°ãƒã‚§ãƒƒã‚¯
        abstract_concept = instruction.get("abstract_concept", "")
        
        prompt_messages = [
            SystemMessage(content=f"""ã‚ãªãŸã¯1on1ã®å¯¾è©±åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚

ç¾åœ¨ã®æ–‡è„ˆï¼š
- ä¸Šå¸ãŒæ–°äººã«ã€Œ{abstract_concept}ã€ã«ã¤ã„ã¦è³ªå•ã‚„æŒ‡å°ã‚’ã—ã¦ã„ã¾ã™
- æ–°äººå–¶æ¥­ãƒãƒ³ãŒå›ç­”ã—ã¾ã—ãŸ

æ–°äººã®å›ç­”ã‚’åˆ†æã—ã€ä»¥ä¸‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ï¼š

ã€é‡è¦ãªåˆ¤å®šåŸºæº–ã€‘:
1. æ–°äººãŒè‡ªåˆ†ã®çµŒé¨“ã‚„ä½“é¨“ã‚’å…±æœ‰ã—ã¦ã„ã‚‹å ´åˆ â†’ è¦æ±‚ã§ã¯ãªã„
   ä¾‹: "ä¾‹ãˆã°ã€ç§ã¯ã€œã—ã¾ã—ãŸ", "å®Ÿéš›ã«ã€œã‚’ä½œæˆã—ã¾ã—ãŸ", "ã“ã‚Œã¾ã§ã«ã€œã—ãŸçµŒé¨“ãŒã‚ã‚Šã¾ã™"
   
2. æ–°äººãŒå…·ä½“çš„ãªè³‡æ–™ã‚„ä¾‹ã‚’æ±‚ã‚ã¦ã„ã‚‹å ´åˆ â†’ è¦æ±‚ã§ã‚ã‚‹
   ä¾‹: "ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„", "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãã ã•ã„", "å‚è€ƒè³‡æ–™ãŒæ¬²ã—ã„ã§ã™"

3. æ–°äººãŒè³ªå•ã‚’ã—ã¦ã„ã‚‹å ´åˆ â†’ è¦æ±‚ã§ã¯ãªã„ (æƒ…å ±åé›†)
   ä¾‹: "ã€œã¯ã©ã†ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ", "ã€œã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"

å›ç­”å½¢å¼ï¼š
```json
{{
  "has_request": true/false,
  "request_type": "è¦æ±‚ã®ç¨®é¡ï¼ˆexample_request/template_request/reference_request/knowledge_request/help_requestï¼‰",
  "confidence": 0.0-1.0,
  "reasoning": "åˆ¤å®šç†ç”±ã‚’ç°¡æ½”ã«",
  "is_experience_sharing": true/false
}}
```"""),
            HumanMessage(content=f"æ–°äººã®å›ç­”: {user_response}")
        ]
        
        try:
            response = await self.llm.ainvoke(prompt_messages)
            response_text = response.content.strip()
            
            # JSONã‚’æŠ½å‡º
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                if json_end != -1:
                    response_text = response_text[json_start:json_end].strip()
            
            result = json.loads(response_text)
            
            # çµŒé¨“å…±æœ‰ã¨ã—ã¦åˆ¤å®šã•ã‚ŒãŸå ´åˆã¯è¦æ±‚ã§ã¯ãªã„
            if result.get("is_experience_sharing", False):
                return None
            
            # è¦æ±‚ã¨ã—ã¦åˆ¤å®šã•ã‚Œã€ååˆ†ãªä¿¡é ¼åº¦ãŒã‚ã‚‹å ´åˆã®ã¿å‡¦ç†
            if result.get("has_request", False) and result.get("confidence", 0) > 0.7:
                return {
                    "type": result.get("request_type", "example_request"),
                    "original_request": user_response,
                    "abstract_concept": abstract_concept,
                    "confidence": result.get("confidence", 0)
                }
            
            return None
            
        except Exception:
            return None
    
    async def _handle_specific_user_request(
        self,
        user_request: Dict[str, str],
        instruction: Dict[str, Any],
        session_id: str,
        db_session: Any
    ) -> Dict[str, Any]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…·ä½“çš„è¦æ±‚ã«å¿œç­”"""
        
        request_type = user_request.get("type", "")
        abstract_concept = user_request.get("abstract_concept", "")
        original_request = user_request.get("original_request", "")
        
        if request_type in ["example_request", "template_request", "reference_request", "knowledge_request"]:
            # ç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å®Ÿä¾‹ã‚’æ¤œç´¢ãƒ»æä¾›
            print(f"DEBUG: Processing user request - concept: '{abstract_concept}', type: '{request_type}'")
            
            knowledge_response = await self._provide_knowledge_examples(
                abstract_concept, request_type, db_session
            )
            
            print(f"DEBUG: Final knowledge_response contains markdown: {'```markdown' in knowledge_response}")
            
            return {
                "type": "knowledge_provision",
                "knowledge_response": knowledge_response,
                "instruction_being_clarified": instruction,
                "stage": "knowledge_provision",
                "stage_description": f"ğŸ“š ç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸æä¾›: ã€Œ{abstract_concept}ã€ã®å®Ÿä¾‹",
                "original_request": original_request,
                "follow_up": "ã“ã®å®Ÿä¾‹ã‚’å‚è€ƒã«ã€ã‚ãªãŸã®çµŒé¨“ã‚„çŠ¶æ³ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚å¯¾è©±ã‚’ç¶šã‘ã¦ã‚ˆã‚Šå…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã—ã¾ã—ã‚‡ã†ã€‚"
            }
        else:
            # ãã®ä»–ã®è¦æ±‚ã¸ã®å¯¾å¿œ
            return {
                "type": "request_acknowledgment", 
                "message": f"ã€Œ{original_request}ã€ã¨ã„ã†ã”è¦æ±‚ã‚’æ‰¿ã‚Šã¾ã—ãŸã€‚ã€Œ{abstract_concept}ã€ã«ã¤ã„ã¦ã€ã¾ãšåŸºæœ¬çš„ãªç†è§£ã‚’æ·±ã‚ã¦ã‹ã‚‰ã€ã‚ˆã‚Šå…·ä½“çš„ãªæ”¯æ´ã‚’æä¾›ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚",
                "instruction_being_clarified": instruction,
                "stage": "request_acknowledgment"
            }
    
    async def _provide_knowledge_examples(
        self,
        abstract_concept: str,
        request_type: str,
        db_session: Any
    ) -> str:
        """ç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å®Ÿä¾‹ã‚’æä¾›"""
        
        # ç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆå®Ÿè£…ä¾‹ï¼‰
        knowledge_examples = await self._search_knowledge_base(
            abstract_concept, request_type, db_session
        )
        
        print(f"DEBUG: Knowledge examples found: {len(knowledge_examples)}")
        
        if knowledge_examples:
            formatted_examples = self._format_knowledge_examples(
                knowledge_examples, abstract_concept, request_type
            )
            print(f"DEBUG: Formatted examples contains markdown: {'```markdown' in formatted_examples}")
            print(f"DEBUG: Formatted examples preview: {formatted_examples[:300]}...")
            return formatted_examples
        else:
            # ãƒŠãƒ¬ãƒƒã‚¸ãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            print(f"DEBUG: No knowledge found, using synthetic examples")
            synthetic_result = await self._generate_synthetic_examples(abstract_concept, request_type)
            print(f"DEBUG: Synthetic result contains markdown: {'```markdown' in synthetic_result}")
            return synthetic_result
    
    async def _search_knowledge_base(
        self,
        abstract_concept: str,
        request_type: str,
        db_session: Any
    ) -> List[Dict[str, Any]]:
        """ç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ¤œç´¢"""
        
        # å®Ÿéš›ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ¤œç´¢å®Ÿè£…
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚„ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é–¢é€£è³‡æ–™ã‚’æ¤œç´¢
            # ä¾‹: SELECT * FROM knowledge_base WHERE concept LIKE %abstract_concept%
            
            # é«˜å“è³ªãªã‚µãƒ³ãƒ—ãƒ«ãƒŠãƒ¬ãƒƒã‚¸ï¼ˆå®Ÿéš›ã®æœ‰ç”¨ä¾‹ï¼‰
            knowledge_samples = {
                "ä¼ã‚ã‚‹è³‡æ–™ä½œæˆ": [
                    {
                        "title": "é¡§å®¢èª²é¡Œè§£æ±ºå‹ææ¡ˆè³‡æ–™ï¼ˆãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ç‰ˆï¼‰",
                        "content": """```markdown
# [é¡§å®¢å]æ§˜ æ¥­å‹™åŠ¹ç‡åŒ–ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ææ¡ˆæ›¸

**ææ¡ˆæ—¥**: 2024å¹´12æœˆXXæ—¥  
**ææ¡ˆè€…**: å–¶æ¥­éƒ¨ [æ‹…å½“è€…å]  
**æœ‰åŠ¹æœŸé™**: 2025å¹´1æœˆæœ«ã¾ã§

---

## 1. ç¾çŠ¶èª²é¡Œã®æ•´ç†

### ğŸ” ãƒ’ã‚¢ãƒªãƒ³ã‚°çµæœ
- **ãƒ‡ãƒ¼ã‚¿é›†è¨ˆä½œæ¥­**: æœˆæœ«ã«3æ—¥é–“ã®æ‰‹ä½œæ¥­ãŒç™ºç”Ÿ
- **ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ**: Excelä½œæ¥­ã§é€±10æ™‚é–“ã‚’æ¶ˆè²»  
- **æƒ…å ±å…±æœ‰**: éƒ¨ç½²é–“ã§ã®é€£æºã«æ™‚é–“ãŒã‹ã‹ã‚‹

### ğŸ“Š èª²é¡Œã®å®šé‡åŒ–
| é …ç›® | ç¾çŠ¶ | ç›®æ¨™ |
|------|------|------|
| ãƒ‡ãƒ¼ã‚¿é›†è¨ˆæ™‚é–“ | 24æ™‚é–“/æœˆ | 2æ™‚é–“/æœˆ |
| ãƒ¬ãƒãƒ¼ãƒˆä½œæˆæ™‚é–“ | 40æ™‚é–“/æœˆ | 10æ™‚é–“/æœˆ |
| ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿç‡ | 5% | 0.5% |

---

## 2. è§£æ±ºç­–ã®ã”ææ¡ˆ

### ğŸ’¡ ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³æ¦‚è¦
**[è£½å“å]** ã«ã‚ˆã‚‹æ¥­å‹™è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®å°å…¥

#### Before â†’ After
- **æ‰‹ä½œæ¥­ãƒ‡ãƒ¼ã‚¿é›†è¨ˆ** â†’ **è‡ªå‹•ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»åŠ å·¥**
- **Excelæ‰‹ä½œæ¥­** â†’ **ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ**
- **ãƒ¡ãƒ¼ãƒ«ãƒ»é›»è©±é€£æº** â†’ **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æƒ…å ±å…±æœ‰**

### ğŸ¯ å°å…¥åŠ¹æœ
```
æœˆé–“å·¥æ•°å‰Šæ¸›: 62æ™‚é–“ â†’ 12æ™‚é–“ (80%å‰Šæ¸›)
å¹´é–“ã‚³ã‚¹ãƒˆåŠ¹æœ: ç´„480ä¸‡å††ã®äººä»¶è²»å‰Šæ¸›
ç²¾åº¦å‘ä¸Š: ã‚¨ãƒ©ãƒ¼ç‡ 5% â†’ 0.5%
```

---

## 3. å°å…¥ãƒ—ãƒ­ã‚»ã‚¹

### ğŸ“… 3ãƒ¶æœˆå°å…¥è¨ˆç”»

#### Phase 1: åŸºç›¤æ§‹ç¯‰ (1ãƒ¶æœˆç›®)
- [ ] ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒæ§‹ç¯‰
- [ ] æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç§»è¡Œæº–å‚™
- [ ] æ‹…å½“è€…å‘ã‘ç ”ä¿®å®Ÿæ–½

#### Phase 2: æ®µéšå°å…¥ (2ãƒ¶æœˆç›®)  
- [ ] ãƒ‡ãƒ¼ã‚¿é›†è¨ˆæ©Ÿèƒ½ã®ç¨¼åƒé–‹å§‹
- [ ] ãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆã®é‹ç”¨é–‹å§‹
- [ ] ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†

#### Phase 3: æœ¬æ ¼é‹ç”¨ (3ãƒ¶æœˆç›®)
- [ ] å…¨æ©Ÿèƒ½ã®æœ¬æ ¼é‹ç”¨
- [ ] é‹ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«æ•´å‚™
- [ ] åŠ¹æœæ¸¬å®šãƒ»æ”¹å–„ææ¡ˆ

### ğŸ’° æŠ•è³‡å›å
```
åˆæœŸæŠ•è³‡: 200ä¸‡å††
æœˆé¡è²»ç”¨: 10ä¸‡å††
æŠ•è³‡å›åæœŸé–“: 6ãƒ¶æœˆ
3å¹´é–“ROI: 350%
```

---

## 4. ã‚µãƒãƒ¼ãƒˆä½“åˆ¶

### ğŸ› ï¸ å°å…¥æ”¯æ´
- **å°‚ä»»SE**: å°å…¥æœŸé–“ä¸­ã®æŠ€è¡“ã‚µãƒãƒ¼ãƒˆ
- **ç ”ä¿®ãƒ—ãƒ­ã‚°ãƒ©ãƒ **: 3å›ã®é›†åˆç ”ä¿® + å€‹åˆ¥ãƒ•ã‚©ãƒ­ãƒ¼
- **ãƒ˜ãƒ«ãƒ—ãƒ‡ã‚¹ã‚¯**: å¹³æ—¥9-18æ™‚ã®é›»è©±ãƒ»ãƒ¡ãƒ¼ãƒ«ã‚µãƒãƒ¼ãƒˆ

### ğŸ“ ç·Šæ€¥æ™‚å¯¾å¿œ
- **24æ™‚é–“ç›£è¦–**: ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒçŠ¶æ³ã®å¸¸æ™‚ç›£è¦–
- **1æ™‚é–“ä»¥å†…å¯¾å¿œ**: ç·Šæ€¥æ™‚ã®åˆæœŸå¯¾å¿œä¿è¨¼
- **æœˆæ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼**: é‹ç”¨çŠ¶æ³ã®å®šæœŸç¢ºèª

---

## 5. æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### ğŸš€ ä»Šå¾Œã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
1. **12æœˆ20æ—¥ã¾ã§**: ã”æ¤œè¨ãƒ»ã”è³ªå•å¯¾å¿œ
2. **12æœˆ25æ—¥**: æœ€çµ‚ææ¡ˆæ›¸ã®ã”æç¤º  
3. **1æœˆ10æ—¥**: å¥‘ç´„ç· çµï¼ˆç›®æ¨™ï¼‰
4. **2æœˆ1æ—¥**: å°å…¥é–‹å§‹

### âœ… ä»Šå›æ±ºã‚ã¦ã„ãŸã ããŸã„ã“ã¨
- [ ] ææ¡ˆå†…å®¹ã«ã¤ã„ã¦ã®ã”æ‰¿èª
- [ ] å°å…¥æ™‚æœŸã®ã”ç¢ºèª
- [ ] æ¬¡å›æ‰“ã¡åˆã‚ã›æ—¥ç¨‹ã®èª¿æ•´

---

**ãŠå•ã„åˆã‚ã›**  
å–¶æ¥­éƒ¨ [æ‹…å½“è€…å]  
ğŸ“§ [email@company.com]  
ğŸ“ 090-XXXX-XXXX
```

**ã“ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä½¿ã„æ–¹**:
1. [ã€€]å†…ã‚’å®Ÿéš›ã®é¡§å®¢æƒ…å ±ã«ç½®ãæ›ãˆ
2. æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã¯å¿…ãšæ ¹æ‹ è³‡æ–™ã‚’æº–å‚™
3. é¡§å®¢ã®æ¥­ç•Œç”¨èªã‚’ç©æ¥µçš„ã«ä½¿ç”¨
4. å°åˆ·æ™‚ã¯A4ã§5-6ãƒšãƒ¼ã‚¸ã«åã¾ã‚‹ã‚ˆã†èª¿æ•´""",
                        "author": "å–¶æ¥­éƒ¨ ç”°æ‘èª²é•·",
                        "success_rate": "ææ¡ˆæˆåŠŸç‡ 85%",
                        "usage_frequency": "æœˆ15ä»¶ä½¿ç”¨",
                        "tags": ["ææ¡ˆè³‡æ–™", "æˆåŠŸäº‹ä¾‹", "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"]
                    },
                    {
                        "title": "å–¶æ¥­ææ¡ˆæ›¸ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆç°¡æ½”ç‰ˆï¼‰",
                        "content": """```markdown
# å–¶æ¥­ææ¡ˆæ›¸ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

## ğŸ“‹ åŸºæœ¬æƒ…å ±
**é¡§å®¢å**: [ä¼šç¤¾å éƒ¨ç½²å æ‹…å½“è€…å]  
**ææ¡ˆè€…**: [è‡ªç¤¾å æ‹…å½“è€…å]  
**ææ¡ˆæ—¥**: [YYYY/MM/DD]

---

## ğŸ¯ ææ¡ˆæ¦‚è¦ï¼ˆ30ç§’ã§ä¼ã‚ã‚‹ï¼‰
**ãŠå›°ã‚Šã”ã¨**: [é¡§å®¢ã®èª²é¡Œã‚’1è¡Œã§]  
**è§£æ±ºç­–**: [ææ¡ˆå†…å®¹ã‚’1è¡Œã§]  
**åŠ¹æœ**: [æ•°å€¤ã§ç¤ºã™ãƒ¡ãƒªãƒƒãƒˆ]

ä¾‹ï¼š
- **ãŠå›°ã‚Šã”ã¨**: æœˆæœ«ã®å£²ä¸Šé›†è¨ˆã«3æ—¥ã‹ã‹ã£ã¦ã„ã‚‹
- **è§£æ±ºç­–**: è‡ªå‹•é›†è¨ˆã‚·ã‚¹ãƒ†ãƒ ã§å³åº§ã«å®Œäº†
- **åŠ¹æœ**: å·¥æ•°90%å‰Šæ¸›ã€æ­£ç¢ºæ€§99.9%å‘ä¸Š

---

## ğŸ“Š ç¾çŠ¶åˆ†æ

### ãƒ’ã‚¢ãƒªãƒ³ã‚°å†…å®¹
| é …ç›® | ç¾çŠ¶ | èª²é¡Œ |
|------|------|------|
| [æ¥­å‹™A] | [ç¾åœ¨ã®çŠ¶æ³] | [å›°ã£ã¦ã„ã‚‹ã“ã¨] |
| [æ¥­å‹™B] | [ç¾åœ¨ã®çŠ¶æ³] | [å›°ã£ã¦ã„ã‚‹ã“ã¨] |
| [æ¥­å‹™C] | [ç¾åœ¨ã®çŠ¶æ³] | [å›°ã£ã¦ã„ã‚‹ã“ã¨] |

### å®šé‡çš„ãªèª²é¡Œ
```
æ™‚é–“: XXæ™‚é–“/æœˆ â†’ YYæ™‚é–“/æœˆã¸çŸ­ç¸®ç›®æ¨™
ã‚³ã‚¹ãƒˆ: XXä¸‡å††/æœˆ â†’ YYä¸‡å††/æœˆã¸å‰Šæ¸›ç›®æ¨™  
å“è³ª: ã‚¨ãƒ©ãƒ¼ç‡XX% â†’ YY%ã¸æ”¹å–„ç›®æ¨™
```

---

## ğŸ’¡ è§£æ±ºææ¡ˆ

### Before â†’ After
| é …ç›® | Beforeï¼ˆç¾çŠ¶ï¼‰ | Afterï¼ˆæ”¹å–„å¾Œï¼‰ | åŠ¹æœ |
|------|----------------|-----------------|------|
| [é …ç›®1] | [ç¾çŠ¶] | [æ”¹å–„å¾Œ] | [åŠ¹æœ] |
| [é …ç›®2] | [ç¾çŠ¶] | [æ”¹å–„å¾Œ] | [åŠ¹æœ] |
| [é …ç›®3] | [ç¾çŠ¶] | [æ”¹å–„å¾Œ] | [åŠ¹æœ] |

### ğŸ“ˆ ROIè¨ˆç®—
```
åˆæœŸæŠ•è³‡: XXXä¸‡å††
æœˆé¡è²»ç”¨: XXä¸‡å††
å¹´é–“åŠ¹æœ: XXXä¸‡å††
æŠ•è³‡å›åæœŸé–“: X.Xå¹´
3å¹´é–“ROI: XXX%
```

---

## ğŸ—“ï¸ å°å…¥ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

| ãƒ•ã‚§ãƒ¼ã‚º | æœŸé–“ | å†…å®¹ | æˆæœç‰© |
|----------|------|------|--------|
| æº–å‚™ | 1é€±é–“ | [æº–å‚™å†…å®¹] | [æˆæœç‰©] |
| å°å…¥ | 2é€±é–“ | [å°å…¥å†…å®¹] | [æˆæœç‰©] |
| é‹ç”¨ | 1é€±é–“ | [é‹ç”¨å†…å®¹] | [æˆæœç‰©] |

---

## ğŸ¤ æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

### ä»Šå›æ±ºã‚ã¦ã„ãŸã ããŸã„ã“ã¨
- [ ] ææ¡ˆå†…å®¹ã¸ã®ã”æ‰¿èª
- [ ] å°å…¥æ™‚æœŸã®ã”ç›¸è«‡  
- [ ] äºˆç®—ç¯„å›²ã®ã”ç¢ºèª

### æ¬¡å›ã¾ã§ã®å®¿é¡Œ
**å¼Šç¤¾**: [ã“ã¡ã‚‰ã§ã‚„ã‚‹ã“ã¨]  
**ãŠå®¢æ§˜**: [ãŠå®¢æ§˜ã«ãŠé¡˜ã„ã—ãŸã„ã“ã¨]

### æ¬¡å›æ‰“ã¡åˆã‚ã›
**æ—¥æ™‚**: [å€™è£œæ—¥ç¨‹]  
**å ´æ‰€**: [å ´æ‰€]  
**è­°é¡Œ**: [è©±ã—åˆã†å†…å®¹]

---

**é€£çµ¡å…ˆ**: [æ‹…å½“è€…å] / [é›»è©±] / [ãƒ¡ãƒ¼ãƒ«]
```

**ä½¿ç”¨ã‚¬ã‚¤ãƒ‰**:
1. [ã€€]å†…ã‚’å®Ÿéš›ã®å†…å®¹ã«ç½®ãæ›ãˆã¦ä½¿ç”¨
2. æ•°å€¤ã¯å¿…ãšæ ¹æ‹ è³‡æ–™ã‚’ç”¨æ„
3. å°‚é–€ç”¨èªã¯é¡§å®¢ã®æ¥­ç•Œç”¨èªã«åˆã‚ã›ã‚‹
4. A4ã§3-4ãƒšãƒ¼ã‚¸ã«åã¾ã‚‹ã‚ˆã†èª¿æ•´""",
                        "author": "å–¶æ¥­éƒ¨ å±±ç”°éƒ¨é•·",
                        "success_rate": "è³‡æ–™è©•ä¾¡å¹³å‡4.8/5.0",
                        "usage_frequency": "å…¨å–¶æ¥­ãŒä½¿ç”¨",
                        "tags": ["ãƒ‡ãƒ¼ã‚¿æ´»ç”¨", "ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ", "å®Ÿè·µçš„"]
                    }
                ],
                "ã‚¹ãƒˆãƒ¼ãƒªãƒ¼æ€§": [
                    {
                        "title": "é¡§å®¢ã®ä¸€æ—¥ã‚¹ãƒˆãƒ¼ãƒªãƒ¼å‹ãƒ—ãƒ¬ã‚¼ãƒ³",
                        "content": """**ã‚¹ãƒˆãƒ¼ãƒªãƒ¼å±•é–‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**:

**å°å…¥éƒ¨**:ã€Œâ—‹â—‹éƒ¨é•·ã®ä¸€æ—¥ã‚’æƒ³åƒã—ã¦ã¿ã¦ãã ã•ã„ã€

**å•é¡Œæèµ·**:
- æœ9æ™‚: å£²ä¸Šå ±å‘Šã®æº–å‚™ã«30åˆ†
- 10æ™‚: ãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ç¢ºã§ä¼šè­°ãŒç´›ç³¾
- åˆå¾Œ: æ‰‹ä½œæ¥­ã§ã®ãƒ‡ãƒ¼ã‚¿é›†è¨ˆãŒ3æ™‚é–“
- å¤•æ–¹: æ®‹æ¥­ã§ã‚ˆã†ã‚„ãè³‡æ–™å®Œæˆ

**è§£æ±ºæç¤º**:
ã€Œã‚‚ã—ã€ã“ã®ä½œæ¥­ãŒ10åˆ†ã§å®Œäº†ã—ãŸã‚‰...ã€
- æœã®30åˆ† â†’ æˆ¦ç•¥æ¤œè¨æ™‚é–“ã«
- ãƒ‡ãƒ¼ã‚¿ä¸æ­£ç¢º â†’ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ­£ç¢ºãƒ‡ãƒ¼ã‚¿
- 3æ™‚é–“ä½œæ¥­ â†’ è‡ªå‹•åŒ–ã§å³åº§ã«å®Œäº†
- æ®‹æ¥­ãªã— â†’ å®šæ™‚ã§æ–°è¦é–‹æ‹“æ´»å‹•

**åŠ¹æœæ¸¬å®š**:
- å·¥æ•°å‰Šæ¸›: æœˆ40æ™‚é–“ â†’ 5æ™‚é–“
- ç²¾åº¦å‘ä¸Š: ã‚¨ãƒ©ãƒ¼ç‡2% â†’ 0.1%
- æº€è¶³åº¦: éƒ¨é•·ã®æ¥­å‹™æº€è¶³åº¦å‘ä¸Š

**è¡Œå‹•å–šèµ·**:
ã€Œæ¥æœˆã‹ã‚‰â—‹â—‹éƒ¨é•·ã«ã“ã®å¿«é©ãªä¸€æ—¥ã‚’éã”ã—ã¦ã„ãŸã ã‘ã¾ã™ã€""",
                        "author": "å–¶æ¥­éƒ¨ éˆ´æœ¨ä¸»ä»»",
                        "success_rate": "æ„Ÿæƒ…çš„å…±æ„Ÿåº¦95%",
                        "usage_frequency": "å¤§å‹æ¡ˆä»¶ã§å¿…é ˆä½¿ç”¨",
                        "tags": ["ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ†ãƒªãƒ³ã‚°", "å…±æ„Ÿå‹", "å¤§å‹æ¡ˆä»¶"]
                    }
                ]
            }
            
            # å®Ÿéš›ã®æ¤œç´¢ï¼ˆæ¦‚å¿µã«ãƒãƒƒãƒã™ã‚‹ãƒŠãƒ¬ãƒƒã‚¸ã‚’æ¢ã™ï¼‰
            matched_knowledge = knowledge_samples.get(abstract_concept, [])
            
            # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°
            print(f"DEBUG: Searching for concept: '{abstract_concept}'")
            print(f"DEBUG: Available concepts: {list(knowledge_samples.keys())}")
            print(f"DEBUG: Matched knowledge count: {len(matched_knowledge)}")
            
            # ã‚ˆã‚Šè‰¯ã„æ¤œç´¢ã®å ´åˆã€å®Ÿéš›ã®DBã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
            # if db_session:
            #     query = f"SELECT * FROM knowledge_base WHERE concept LIKE '%{abstract_concept}%'"
            #     matched_knowledge = db_session.execute(query).fetchall()
            
            return matched_knowledge
            
        except Exception:
            return []
    
    def _format_knowledge_examples(
        self,
        knowledge_examples: List[Dict[str, Any]],
        abstract_concept: str,
        request_type: str
    ) -> str:
        """ãƒŠãƒ¬ãƒƒã‚¸ä¾‹ã‚’é«˜å“è³ªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        
        if request_type == "example_request":
            header = f"ğŸ“š **ã€Œ{abstract_concept}ã€ã®ç¤¾å†…å®Ÿä¾‹**"
        elif request_type == "template_request":
            header = f"ğŸ“‹ **ã€Œ{abstract_concept}ã€ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**"
        elif request_type == "reference_request":
            header = f"ğŸ¯ **ã€Œ{abstract_concept}ã€ã®å‚è€ƒè³‡æ–™**"
        else:
            header = f"ğŸ’¡ **ã€Œ{abstract_concept}ã€ã®ç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸**"
        
        formatted = f"{header}\n\n"
        
        for i, example in enumerate(knowledge_examples, 1):
            title = example.get('title', f'å®Ÿä¾‹{i}')
            content = example.get('content', '')
            author = example.get('author', '')
            success_rate = example.get('success_rate', '')
            usage_frequency = example.get('usage_frequency', '')
            
            formatted += f"**{i}. {title}**\n"
            
            # è©³ç´°å†…å®¹ã‚’ãã®ã¾ã¾è¡¨ç¤º
            if content:
                formatted += f"{content}\n"
            
            # æˆåŠŸæŒ‡æ¨™ã‚„ä½¿ç”¨é »åº¦ãŒã‚ã‚Œã°è¡¨ç¤º
            if success_rate:
                formatted += f"ğŸ“Š æˆæœ: {success_rate}\n"
            if usage_frequency:
                formatted += f"ğŸ“ˆ æ´»ç”¨åº¦: {usage_frequency}\n"
            if author:
                formatted += f"_ä½œæˆè€…: {author}_\n"
            
            formatted += "\n---\n\n"
        
        return formatted
    
    async def _generate_synthetic_examples(
        self,
        abstract_concept: str,
        request_type: str
    ) -> str:
        """ãƒŠãƒ¬ãƒƒã‚¸ãŒãªã„å ´åˆã®é«˜å“è³ªåˆæˆä¾‹ç”Ÿæˆ"""
        
        if request_type == "example_request":
            prompt_content = f"""æ–°äººå–¶æ¥­ãƒãƒ³ãŒã€Œ{abstract_concept}ã€ã®å…·ä½“ä¾‹ã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚

ã™ãã«ä½¿ãˆã‚‹ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã®å®Ÿç”¨çš„ãªä¾‹ã‚’3ã¤æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦è¦ä»¶ã€‘:
- ã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆã§ä½¿ãˆã‚‹ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼
- æ˜æ—¥ã‹ã‚‰å®Ÿè·µã§ãã‚‹ãƒ¬ãƒ™ãƒ«ã®è©³ç´°ã•
- å®Ÿéš›ã®å–¶æ¥­ã‚·ãƒ¼ãƒ³ã§ã®ä½¿ç”¨æ–¹æ³•
- æ•°å€¤ãƒ»æ™‚é–“ãƒ»é »åº¦ã‚’å«ã‚€å…·ä½“æ€§
- [å¤‰æ›´ç®‡æ‰€]ã‚’æ˜ç¤ºã—ã¦ä½¿ã„ã‚„ã™ã

ã€å‡ºåŠ›å½¢å¼ã€‘:
**ä¾‹1: [å…·ä½“çš„ãªã‚¿ã‚¤ãƒˆãƒ«]**
```markdown
[å®Ÿéš›ã«ä½¿ãˆã‚‹ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ]
```
- ä½¿ç”¨å ´é¢: [è©³ç´°ãªã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³]
- ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºç®‡æ‰€: [å¤‰æ›´ã™ã¹ã[ã€€]éƒ¨åˆ†ã®èª¬æ˜]
- æˆåŠŸã®ã‚³ãƒ„: [å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹]
- æ‰€è¦æ™‚é–“: [ä½œæˆã«ã‹ã‹ã‚‹æ™‚é–“]

**ä¾‹2**: [åŒæ§˜ã®å½¢å¼]
**ä¾‹3**: [åŒæ§˜ã®å½¢å¼]"""
        elif request_type == "template_request":
            prompt_content = f"""æ–°äººå–¶æ¥­ãƒãƒ³ãŒã€Œ{abstract_concept}ã€ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚

ã™ãã«ä½¿ãˆã‚‹å®Ÿç”¨çš„ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’3ã¤æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦è¦ä»¶ã€‘:
- ã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆã§ä½¿ãˆã‚‹å½¢å¼
- ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ–¹æ³•ã‚‚èª¬æ˜
- å®Ÿéš›ã®æ–‡è¨€ä¾‹ã‚’å«ã‚€
- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ»æ§‹æˆã‚’å…·ä½“çš„ã«
- ä½¿ç”¨ä¸Šã®æ³¨æ„ç‚¹ã‚‚ä½µè¨˜

ã€å‡ºåŠ›å½¢å¼ã€‘:
**ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ1: [åå‰]**
```
[å®Ÿéš›ã«ä½¿ãˆã‚‹å…·ä½“çš„ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ]
```
ä½¿ç”¨æ–¹æ³•: [è©³ç´°ãªèª¬æ˜]
ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º: [å¤‰æ›´ã™ã¹ãç®‡æ‰€]

**ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ2**: [åŒæ§˜ã®å½¢å¼]
**ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ3**: [åŒæ§˜ã®å½¢å¼]"""
        else:
            prompt_content = f"""æ–°äººå–¶æ¥­ãƒãƒ³ãŒã€Œ{abstract_concept}ã€ã®å‚è€ƒè³‡æ–™ã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚

å®Ÿè·µçš„ã§å­¦ç¿’åŠ¹æœã®é«˜ã„å‚è€ƒä¾‹ã‚’3ã¤æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦è¦ä»¶ã€‘:
- æˆåŠŸäº‹ä¾‹ã®å…·ä½“çš„ãªå†…å®¹
- ãªãœæˆåŠŸã—ãŸã‹ã®åˆ†æ
- æ–°äººãŒçœŸä¼¼ã§ãã‚‹ãƒã‚¤ãƒ³ãƒˆ
- é¿ã‘ã‚‹ã¹ãå¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³
- æ®µéšçš„ãªç¿’å¾—æ–¹æ³•

å®Ÿéš›ã®å–¶æ¥­ç¾å ´ã§å½¹ç«‹ã¤ã€å…·ä½“çš„ã§è©³ç´°ãªå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚"""
        
        prompt_messages = [
            SystemMessage(content=prompt_content),
            HumanMessage(content=f"ã€Œ{abstract_concept}ã€ã«ã¤ã„ã¦ã€æ–°äººå–¶æ¥­ãƒãƒ³ãŒå®Ÿéš›ã«ä½¿ãˆã‚‹å…·ä½“çš„ã§è©³ç´°ãª{request_type}ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚")
        ]
        
        try:
            response = await self.llm.ainvoke(prompt_messages)
            return f"ğŸ’¡ **ã€Œ{abstract_concept}ã€ã®å®Ÿè·µä¾‹**\n\n{response.content.strip()}"
        except Exception:
            return f"ã€Œ{abstract_concept}ã€ã«ã¤ã„ã¦ã€ã‚ˆã‚Šè©³ã—ã„æƒ…å ±ã‚’ãŠèª¿ã¹ã—ã¦å¾Œã»ã©æä¾›ã„ãŸã—ã¾ã™ã€‚ã¾ãšã¯åŸºæœ¬çš„ãªç†è§£ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚"