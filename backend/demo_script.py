#!/usr/bin/env python3
"""
LLM APIãƒ‡ãƒ¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®Ÿéš›ã®OpenAI/Anthropic APIã‚’ä½¿ç”¨ã—ãŸå¯¾è©±ãƒ‡ãƒ¢
"""

import asyncio
import aiohttp
import json
import sys
from typing import Dict, Any

BASE_URL = "http://localhost:8000"

class LLMDemo:
    def __init__(self):
        self.session = None
        self.session_id = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def test_connection(self, provider: str = "openai"):
        """LLMæŽ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        print(f"ðŸ” {provider.upper()} æŽ¥ç¶šãƒ†ã‚¹ãƒˆä¸­...")
        
        try:
            async with self.session.get(f"{BASE_URL}/demo/test-connection/{provider}") as response:
                result = await response.json()
                
                if result["status"] == "success":
                    print(f"âœ… {provider.upper()} æŽ¥ç¶šæˆåŠŸ!")
                    print(f"   ãƒ¢ãƒ‡ãƒ«: {result['model']}")
                    print(f"   ãƒ†ã‚¹ãƒˆçµæžœ: {result['test_response']}")
                    return True
                else:
                    print(f"âŒ {provider.upper()} æŽ¥ç¶šå¤±æ•—: {result['error']}")
                    return False
                    
        except Exception as e:
            print(f"âŒ æŽ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    async def start_demo_session(self, provider: str = "openai"):
        """ãƒ‡ãƒ¢ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹"""
        print(f"\nðŸš€ {provider.upper()} ãƒ‡ãƒ¢ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹...")
        
        request_data = {
            "user_name": "ç”°ä¸­å¤ªéƒŽ",
            "department": "å–¶æ¥­éƒ¨",
            "experience_years": 1,
            "initial_topic": "æ–°è¦é¡§å®¢é–‹æ‹“ã®ã‚¹ã‚­ãƒ«å‘ä¸Š",
            "llm_provider": provider
        }
        
        try:
            async with self.session.post(
                f"{BASE_URL}/demo/start",
                json=request_data
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    self.session_id = result["session_id"]
                    
                    print(f"âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æˆåŠŸ (ID: {self.session_id[:8]}...)")
                    print(f"ðŸ“Š åˆæœŸæƒ…å ±å……è¶³åº¦: {result['completeness_score']}%")
                    print(f"ðŸ’­ ç†ç”±: {result['reasoning']}")
                    print("\nðŸ“ ç”Ÿæˆã•ã‚ŒãŸè³ªå•:")
                    for i, question in enumerate(result["questions"], 1):
                        print(f"   {i}. {question}")
                    
                    return result
                else:
                    error = await response.json()
                    print(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹å¤±æ•—: {error['detail']}")
                    return None
                    
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    async def send_message(self, message: str):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡"""
        if not self.session_id:
            print("âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒé–‹å§‹ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
        
        print(f"\nðŸ’¬ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {message}")
        print("ðŸ¤– AIå¿œç­”ç”Ÿæˆä¸­...")
        
        request_data = {
            "session_id": self.session_id,
            "message": message
        }
        
        try:
            async with self.session.post(
                f"{BASE_URL}/demo/message",
                json=request_data
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    
                    print(f"ðŸ“Š æƒ…å ±å……è¶³åº¦: {result['completeness_score']}%")
                    
                    # æ„Ÿæƒ…åˆ†æžçµæžœ
                    if result.get("sentiment_analysis"):
                        sentiment = result["sentiment_analysis"]
                        print(f"ðŸ˜Š æ„Ÿæƒ…åˆ†æž: {sentiment.get('sentiment', 'N/A')} ({sentiment.get('emotional_state', 'N/A')})")
                    
                    if result["type"] == "follow_up":
                        print("ðŸ“ è¿½åŠ è³ªå•:")
                        for i, question in enumerate(result["questions"], 1):
                            print(f"   {i}. {question}")
                        if result.get("reasoning"):
                            print(f"ðŸ’­ ç†ç”±: {result['reasoning']}")
                    
                    elif result["type"] == "action_plan":
                        print("ðŸŽ¯ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆå®Œäº†!")
                        action_plan = result["action_plan"]
                        print(f"ðŸ“‹ ã‚µãƒžãƒªãƒ¼: {action_plan['summary']}")
                        print("ðŸ“ˆ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ :")
                        for i, item in enumerate(action_plan["action_items"], 1):
                            print(f"   {i}. {item.get('title', 'N/A')}")
                            print(f"      èª¬æ˜Ž: {item.get('description', 'N/A')}")
                            print(f"      å„ªå…ˆåº¦: {item.get('priority', 'N/A')}")
                    
                    return result
                else:
                    error = await response.json()
                    print(f"âŒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡å¤±æ•—: {error['detail']}")
                    return None
                    
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    async def get_session_info(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±å–å¾—"""
        if not self.session_id:
            return None
        
        try:
            async with self.session.get(f"{BASE_URL}/demo/session/{self.session_id}") as response:
                if response.status == 200:
                    return await response.json()
                return None
        except:
            return None

async def interactive_demo():
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢"""
    print("=" * 60)
    print("ðŸ¤– å–¶æ¥­ã‚¹ã‚­ãƒ«å‘ä¸ŠAI - LLMãƒ‡ãƒ¢")
    print("=" * 60)
    
    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠž
    print("\nLLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’é¸æŠžã—ã¦ãã ã•ã„:")
    print("1. OpenAI GPT-3.5-turbo")
    print("2. Anthropic Claude")
    
    while True:
        choice = input("é¸æŠž (1-2): ").strip()
        if choice == "1":
            provider = "openai"
            break
        elif choice == "2":
            provider = "anthropic"
            break
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠžã§ã™")
    
    async with LLMDemo() as demo:
        # æŽ¥ç¶šãƒ†ã‚¹ãƒˆ
        if not await demo.test_connection(provider):
            print("\nâŒ APIæŽ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã®API keyã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
        session_result = await demo.start_demo_session(provider)
        if not session_result:
            return
        
        print("\n" + "="*60)
        print("ðŸ’¬ å¯¾è©±é–‹å§‹! 'quit'ã§çµ‚äº†")
        print("="*60)
        
        # å¯¾è©±ãƒ«ãƒ¼ãƒ—
        while True:
            user_input = input("\nðŸ—£ï¸  ã‚ãªãŸ: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'q']:
                break
            
            if not user_input:
                continue
            
            result = await demo.send_message(user_input)
            
            if result and result["type"] == "action_plan":
                print("\nðŸŽ‰ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ãŒå®Œæˆã—ã¾ã—ãŸ!")
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤º
                session_info = await demo.get_session_info()
                if session_info:
                    print(f"ðŸ“Š ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {session_info['message_count']}")
                
                break
        
        print("\nðŸ‘‹ ãƒ‡ãƒ¢ã‚’çµ‚äº†ã—ã¾ã™ã€‚ãŠç–²ã‚Œã•ã¾ã§ã—ãŸ!")

async def batch_demo():
    """ãƒãƒƒãƒãƒ‡ãƒ¢ï¼ˆã‚µãƒ³ãƒ—ãƒ«ä¼šè©±ï¼‰"""
    print("ðŸ¤– ãƒãƒƒãƒãƒ‡ãƒ¢å®Ÿè¡Œä¸­...")
    
    sample_messages = [
        "æ–°è¦é¡§å®¢ã®é–‹æ‹“ãŒã†ã¾ãã„ã‹ãšã€ã‚¢ãƒã‚¤ãƒ³ãƒˆãƒ¡ãƒ³ãƒˆãŒå–ã‚Œã¾ã›ã‚“ã€‚",
        "é›»è©±ã§ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä¸»ã«ã—ã¦ã„ã¾ã™ãŒã€æ–­ã‚‰ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚",
        "ç›®æ¨™ã¯æœˆã«10ä»¶ã®æ–°è¦é¡§å®¢ç²å¾—ã§ã™ãŒã€ç¾åœ¨ã¯2-3ä»¶ç¨‹åº¦ã§ã™ã€‚",
        "å–¶æ¥­çµŒé¨“ã¯1å¹´ã§ã€ä¸»ã«æ—¢å­˜é¡§å®¢ã®ãƒ•ã‚©ãƒ­ãƒ¼ã‚’ã—ã¦ã„ã¾ã—ãŸã€‚",
        "ä¸Šå¸ã‹ã‚‰ã¯ã‚‚ã£ã¨ç©æ¥µçš„ã«ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã™ã‚‹ã‚ˆã†è¨€ã‚ã‚Œã¦ã„ã¾ã™ã€‚"
    ]
    
    async with LLMDemo() as demo:
        if not await demo.test_connection("openai"):
            print("âŒ APIæŽ¥ç¶šå¤±æ•—")
            return
        
        await demo.start_demo_session("openai")
        
        for message in sample_messages:
            await demo.send_message(message)
            await asyncio.sleep(1)  # APIåˆ¶é™å¯¾ç­–

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    if len(sys.argv) > 1 and sys.argv[1] == "batch":
        asyncio.run(batch_demo())
    else:
        asyncio.run(interactive_demo())

if __name__ == "__main__":
    main()